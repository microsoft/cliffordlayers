{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"install/","title":"Installation Guide","text":"<pre><code>pip install cliffordlayers\n</code></pre>"},{"location":"install/#for-development","title":"For development","text":"clone the repo<pre><code>git clone https://github.com/microsoft/cliffordlayers\n</code></pre> <code>conda</code><code>docker</code> create and activate env<pre><code>cd cliffordlayers\nconda env create --file docker/environment.yml\nconda activate cliffordlayers\n</code></pre> make an editable install<pre><code>pip install -e .\n</code></pre> build docker container<pre><code>cd cliffordlayers/docker\ndocker build -t cliffordlayers .\ncd ..\n</code></pre> run docker container<pre><code>docker run --gpus all -it --rm --user $(id -u):$(id -g) \\\n    -v $(pwd):/code  --workdir /code -e PYTHONPATH=/code \\\n    cliffordlayers:latest\n</code></pre>"},{"location":"research/","title":"Research","text":""},{"location":"research/#research","title":"Research","text":"<p>Following is a list of research papers that have been published using CliffordLayers.</p> <p>If you have used CliffordLayers in your research, and would like it listed here, please add your paper to this file by sending a pull request to the CliffordLayers repository.</p> <p></p> <p> David Ruhe <sup>1</sup>, Jayesh K. Gupta <sup>2</sup>, Steven de Keninck <sup>1</sup>, Max Welling <sup>3</sup>, Johannes Brandstetter <sup>3</sup> <p><sup>1</sup>University of Amsterdam, <sup>2</sup>Microsoft Autonomous Systems and Robotics Research, <sup>3</sup>Microsoft Research AI4Science Abstract: We propose Geometric Clifford Algebra Networks (GCANs) that are based on symmetry group transformations using geometric (Clifford) algebras. GCANs are particularly well-suited for representing and manipulating geometric transformations, often found in dynamical systems. We first review the quintessence of modern (plane-based) geometric algebra, which builds on isometries encoded as elements of the Pin(p,q,r) group. We then propose the concept of group action layers, which linearly combine object transformations using pre-specified group actions. Together with a new activation and normalization scheme, these layers serve as adjustable geometric templates that can be refined via gradient descent. Theoretical advantages are strongly reflected in the modeling of three-dimensional rigid body transformations as well as large-scale fluid dynamics simulations, showing significantly improved performance over traditional methods.</p> <p></p> <p> Johannes Brandstetter <sup>1</sup>, Rianne van den Berg <sup>1</sup>, Max Welling <sup>1</sup>, Jayesh K. Gupta <sup>2</sup> <p><sup>1</sup>Microsoft Research AI4Science, <sup>2</sup>Microsoft Autonomous Systems and Robotics Research Abstract: Partial differential equations (PDEs) see widespread use in sciences and engineering to describe simulation of physical processes as scalar and vector fields interacting and coevolving over time. Due to the computationally expensive nature of their standard solution methods, neural PDE surrogates have become an active research topic to accelerate these simulations. However, current methods do not explicitly take into account the relationship between different fields and their internal components, which are often correlated. Viewing the time evolution of such correlated fields through the lens of multivector fields allows us to overcome these limitations. Multivector fields consist of scalar, vector, as well as higher-order components, such as bivectors and trivectors. Their algebraic properties, such as multiplication, addition and other arithmetic operations can be described by Clifford algebras. To our knowledge, this paper presents the first usage of such multivector representations together with Clifford convolutions and Clifford Fourier transforms in the context of deep learning. The resulting Clifford neural layers are universally applicable and will find direct use in the areas of fluid dynamics, weather forecasting, and the modeling of physical systems in general. We empirically evaluate the benefit of Clifford neural layers by replacing convolution and Fourier operations in common neural PDE surrogates by their Clifford counterparts on two-dimensional Navier-Stokes and weather modeling tasks, as well as three-dimensional Maxwell equations. Clifford neural layers consistently improve generalization capabilities of the tested neural PDE surrogates.</p>"},{"location":"research/#geometric-clifford-algebra-networks","title":"Geometric Clifford Algebra Networks","text":""},{"location":"research/#clifford-neural-layers-for-pde-modeling","title":"Clifford Neural Layers for PDE Modeling","text":""},{"location":"reference/functional/","title":"Functions","text":""},{"location":"reference/functional/#cliffordlayers.nn.functional.batchnorm.clifford_batch_norm","title":"<code>clifford_batch_norm(x, n_blades, running_mean=None, running_cov=None, weight=None, bias=None, training=True, momentum=0.1, eps=1e-05)</code>","text":"<p>Clifford batch normalization for each channel across a batch of data.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>Tensor</code> <p>Input tensor of shape <code>(B, C, *D, I)</code> where I is the blade of the algebra.</p> required <code>n_blades</code> <code>int</code> <p>Number of blades of the Clifford algebra.</p> required <code>running_mean</code> <code>Tensor</code> <p>The tensor with running mean statistics having shape <code>(I, C)</code>.</p> <code>None</code> <code>running_cov</code> <code>Tensor</code> <p>The tensor with running covariance statistics having shape <code>(I, I, C)</code>.</p> <code>None</code> <code>weight</code> <code>Union[Tensor, Parameter]</code> <p>Additional weight tensor which is applied post normalization, and has the shape <code>(I, I, C)</code>.</p> <code>None</code> <code>bias</code> <code>Union[Tensor, Parameter]</code> <p>Additional bias tensor which is applied post normalization, and has the shape <code>(I, C)</code>.</p> <code>None</code> <code>training</code> <code>bool</code> <p>Whether to use the running mean and variance. Defaults to True. Defaults to True.</p> <code>True</code> <code>momentum</code> <code>float</code> <p>Momentum for the running mean and variance. Defaults to 0.1.</p> <code>0.1</code> <code>eps</code> <code>float</code> <p>Epsilon for the running mean and variance. Defaults to 1e-05.</p> <code>1e-05</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>Normalized input of shape <code>(B, C, *D, I)</code></p> Source code in <code>cliffordlayers/nn/functional/batchnorm.py</code> <pre><code>def clifford_batch_norm(\n    x: torch.Tensor,\n    n_blades: int,\n    running_mean: Optional[torch.Tensor] = None,\n    running_cov: Optional[torch.Tensor] = None,\n    weight: Optional[Union[torch.Tensor, nn.Parameter]] = None,\n    bias: Optional[Union[torch.Tensor, nn.Parameter]] = None,\n    training: bool = True,\n    momentum: float = 0.1,\n    eps: float = 1e-05,\n) -&gt; torch.Tensor:\n    \"\"\"Clifford batch normalization for each channel across a batch of data.\n\n    Args:\n        x (torch.Tensor): Input tensor of shape `(B, C, *D, I)` where I is the blade of the algebra.\n        n_blades (int): Number of blades of the Clifford algebra.\n        running_mean (torch.Tensor, optional): The tensor with running mean statistics having shape `(I, C)`.\n        running_cov (torch.Tensor, optional): The tensor with running covariance statistics having shape `(I, I, C)`.\n        weight (Union[torch.Tensor, nn.Parameter], optional): Additional weight tensor which is applied post normalization, and has the shape `(I, I, C)`.\n        bias (Union[torch.Tensor, nn.Parameter], optional): Additional bias tensor which is applied post normalization, and has the shape `(I, C)`.\n        training (bool, optional): Whether to use the running mean and variance. Defaults to True. Defaults to True.\n        momentum (float, optional): Momentum for the running mean and variance. Defaults to 0.1.\n        eps (float, optional): Epsilon for the running mean and variance. Defaults to 1e-05.\n\n    Returns:\n        (torch.Tensor): Normalized input of shape `(B, C, *D, I)`\n    \"\"\"\n\n    # Check arguments.\n    assert (running_mean is None and running_cov is None) or (running_mean is not None and running_cov is not None)\n    assert (weight is None and bias is None) or (weight is not None and bias is not None)\n\n    # Whiten and apply affine transformation\n    _, C, *_, I = x.shape\n    assert I == n_blades\n    x_norm = whiten_data(\n        x,\n        training=training,\n        running_mean=running_mean,\n        running_cov=running_cov,\n        momentum=momentum,\n        eps=eps,\n    )\n    if weight is not None and bias is not None:\n        # Check if weight and bias tensors are of correct shape.\n        assert weight.shape == (I, I, C)\n        assert bias.shape == (I, C)\n        # Unsqueeze weight and bias for each dimension except the channel dimension.\n        shape = 1, C, *([1] * (x.dim() - 3))\n        weight = weight.reshape(I, I, *shape)\n        # Apply additional affine transformation post normalization.\n        weight_idx = list(range(weight.dim()))\n        # TODO: weight multiplication should be changed to geometric product.\n        weight = weight.permute(*weight_idx[2:], *weight_idx[:2])\n        x_norm = weight.matmul(x_norm[..., None]).squeeze(-1) + bias.reshape(*shape, I)\n\n    return x_norm\n</code></pre>"},{"location":"reference/functional/#cliffordlayers.nn.functional.batchnorm.complex_batch_norm","title":"<code>complex_batch_norm(x, running_mean=None, running_cov=None, weight=None, bias=None, training=True, momentum=0.1, eps=1e-05)</code>","text":"<p>Applies complex-valued Batch Normalization as described in (Trabelsi et al., 2018) for each channel across a batch of data.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>Tensor</code> <p>The input complex-valued data is expected to be at least 2d, with shape <code>(B, C, *D)</code>, where <code>B</code> is the batch dimension, <code>C</code> the channels/features, and *D the remaining dimensions (if present).</p> required <code>running_mean</code> <code>Union[Tensor, Parameter]</code> <p>The tensor with running mean statistics having shape <code>(2, C)</code>.</p> <code>None</code> <code>running_cov</code> <code>Union[Tensor, Parameter]</code> <p>The tensor with running real-imaginary covariance statistics having shape <code>(2, 2, C)</code>.</p> <code>None</code> <code>weight</code> <code>Tensor</code> <p>Additional weight tensor which is applied post normalization, and has the shape <code>(2, 2, C)</code>.</p> <code>None</code> <code>bias</code> <code>Tensor</code> <p>Additional bias tensor which is applied post normalization, and has the shape <code>(2, C)</code>.</p> <code>None</code> <code>training</code> <code>bool</code> <p>Whether to use the running mean and variance. Defaults to <code>True</code>.</p> <code>True</code> <code>momentum</code> <code>float</code> <p>Momentum for the running mean and variance. Defaults to <code>0.1</code>.</p> <code>0.1</code> <code>eps</code> <code>float</code> <p>Epsilon for the running mean and variance. Defaults to <code>1e-05</code>.</p> <code>1e-05</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>Normalized input as complex tensor of shape <code>(B, C, *D)</code>.</p> Source code in <code>cliffordlayers/nn/functional/batchnorm.py</code> <pre><code>def complex_batch_norm(\n    x: torch.Tensor,\n    running_mean: Optional[torch.Tensor] = None,\n    running_cov: Optional[torch.Tensor] = None,\n    weight: Optional[Union[torch.Tensor, nn.Parameter]] = None,\n    bias: Optional[Union[torch.Tensor, nn.Parameter]] = None,\n    training: bool = True,\n    momentum: float = 0.1,\n    eps: float = 1e-05,\n) -&gt; torch.Tensor:\n    \"\"\"Applies complex-valued Batch Normalization as described in\n    (Trabelsi et al., 2018) for each channel across a batch of data.\n\n    Args:\n        x (torch.Tensor): The input complex-valued data is expected to be at least 2d, with shape `(B, C, *D)`, where `B` is the batch dimension, `C` the channels/features, and *D the remaining dimensions (if present).\n\n        running_mean (Union[torch.Tensor, nn.Parameter], optional): The tensor with running mean statistics having shape `(2, C)`.\n        running_cov (Union[torch.Tensor, nn.Parameter], optional): The tensor with running real-imaginary covariance statistics having shape `(2, 2, C)`.\n        weight (torch.Tensor, optional): Additional weight tensor which is applied post normalization, and has the shape `(2, 2, C)`.\n        bias (torch.Tensor, optional): Additional bias tensor which is applied post normalization, and has the shape `(2, C)`.\n        training (bool, optional): Whether to use the running mean and variance. Defaults to `True`.\n        momentum (float, optional): Momentum for the running mean and variance. Defaults to `0.1`.\n        eps (float, optional): Epsilon for the running mean and variance. Defaults to `1e-05`.\n\n    Returns:\n        (torch.Tensor): Normalized input as complex tensor of shape `(B, C, *D)`.\n    \"\"\"\n\n    # Check arguments.\n    assert (running_mean is None and running_cov is None) or (running_mean is not None and running_cov is not None)\n    assert (weight is None and bias is None) or (weight is not None and bias is not None)\n    x = torch.view_as_real(x)\n    _, C, *_, I = x.shape\n    assert I == 2\n\n    # Whiten and apply affine transformation.\n    x_norm = whiten_data(\n        x,\n        training,\n        running_mean,\n        running_cov,\n        momentum,\n        eps,\n    )\n    if weight is not None and bias is not None:\n        # Check if weight and bias tensors are of correct shape.\n        assert weight.shape == (2, 2, C)\n        assert bias.shape == (2, C)\n        # Unsqueeze weight and bias for each dimension except the channel dimension.\n        shape = 1, C, *([1] * (x.dim() - 3))\n        weight = weight.reshape(2, 2, *shape)\n        # Apply additional affine transformation post normalization.\n        weight_idx = list(range(weight.dim()))\n        # TODO weight multiplication should be changed to complex product.\n        weight = weight.permute(*weight_idx[2:], *weight_idx[:2])\n        x_norm = weight.matmul(x_norm[..., None]).squeeze(-1) + bias.reshape(*shape, 2)\n\n    return torch.view_as_complex(x_norm)\n</code></pre>"},{"location":"reference/functional/#cliffordlayers.nn.functional.batchnorm.whiten_data","title":"<code>whiten_data(x, training=True, running_mean=None, running_cov=None, momentum=0.1, eps=1e-05)</code>","text":"<p>Jointly whiten features in tensors <code>(B, C, *D, I)</code>: take n_blades(I)-dim vectors and whiten individually for each channel dimension C over <code>(B, *D)</code>. I is the number of blades in the respective Clifford algebra, e.g. I = 2 for complex numbers.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>Tensor</code> <p>The tensor to whiten.</p> required <code>training</code> <code>bool</code> <p>Wheter to update the running mean and covariance. Defaults to <code>True</code>.</p> <code>True</code> <code>running_mean</code> <code>Tensor</code> <p>The running mean of shape <code>(I, C). Defaults to</code>None`.</p> <code>None</code> <code>running_cov</code> <code>Tensor</code> <p>The running covariance of shape <code>(I, I, C)</code> Defaults to <code>None</code>.</p> <code>None</code> <code>momentum</code> <code>float</code> <p>The momentum to use for the running mean and covariance. Defaults to <code>0.1</code>.</p> <code>0.1</code> <code>eps</code> <code>float</code> <p>A small number to add to the covariance. Defaults to 1e-5.</p> <code>1e-05</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>Whitened data of shape <code>(B, C, *D, I)</code>.</p> Source code in <code>cliffordlayers/nn/functional/batchnorm.py</code> <pre><code>def whiten_data(\n    x: torch.Tensor,\n    training: bool = True,\n    running_mean: Optional[torch.Tensor] = None,\n    running_cov: Optional[torch.Tensor] = None,\n    momentum: float = 0.1,\n    eps: float = 1e-5,\n) -&gt; torch.Tensor:\n    \"\"\"Jointly whiten features in tensors `(B, C, *D, I)`: take n_blades(I)-dim vectors\n    and whiten individually for each channel dimension C over `(B, *D)`.\n    I is the number of blades in the respective Clifford algebra, e.g. I = 2 for complex numbers.\n\n    Args:\n        x (torch.Tensor): The tensor to whiten.\n        training (bool, optional): Wheter to update the running mean and covariance. Defaults to `True`.\n        running_mean (torch.Tensor, optional): The running mean of shape `(I, C). Defaults to `None`.\n        running_cov (torch.Tensor, optional): The running covariance of shape `(I, I, C)` Defaults to `None`.\n        momentum (float, optional): The momentum to use for the running mean and covariance. Defaults to `0.1`.\n        eps (float, optional): A small number to add to the covariance. Defaults to 1e-5.\n\n    Returns:\n        (torch.Tensor): Whitened data of shape `(B, C, *D, I)`.\n    \"\"\"\n\n    assert x.dim() &gt;= 3\n    # Get whitening shape of [1, C, ...]\n    _, C, *_, I = x.shape\n    B_dim, C_dim, *D_dims, I_dim = range(len(x.shape))\n    shape = 1, C, *([1] * (x.dim() - 3))\n\n    # Get feature mean.\n    if not (running_mean is None or running_mean.shape == (I, C)):\n        raise ValueError(f\"Running_mean expected to be none, or of shape ({I}, {C}).\")\n    if training or running_mean is None:\n        mean = x.mean(dim=(B_dim, *D_dims))\n        if running_mean is not None:\n            running_mean += momentum * (mean.data.permute(1, 0) - running_mean)\n    else:\n        mean = running_mean.permute(1, 0)\n\n    # Get feature covariance.\n    x = x - mean.reshape(*shape, I)\n    if not (running_cov is None or running_cov.shape == (I, I, C)):\n        raise ValueError(f\"Running_cov expected to be none, or of shape ({I}, {I}, {C}).\")\n    if training or running_cov is None:\n        # B, C, *D, I -&gt; C, I, B, *D\n        X = x.permute(C_dim, I_dim, B_dim, *D_dims).flatten(2, -1)\n        # Covariance XX^T matrix of shape C x I x I\n        cov = torch.matmul(X, X.transpose(-1, -2)) / X.shape[-1]\n        if running_cov is not None:\n            running_cov += momentum * (cov.data.permute(1, 2, 0) - running_cov)\n\n    else:\n        cov = running_cov.permute(2, 0, 1)\n\n    # Upper triangle Cholesky decomposition of covariance matrix: U^T U = Cov\n    # eye = eps * torch.eye(I, device=cov.device, dtype=cov.dtype).unsqueeze(0)\n    # Modified the scale of eps to help prevent the occurence of negative-definite matrices\n    # 1e-5 may not fit the scale of matrices with large numbers\n    max_values = torch.amax(cov, dim=(1, 2))\n    A = torch.eye(cov.shape[-1], device=cov.device, dtype=cov.dtype)\n    eye = eps * torch.einsum('ij,k-&gt;kij', A, max_values)\n    U = torch.linalg.cholesky(cov + eye).mH\n    # Invert Cholesky decomposition, returns tensor of shape [B, C, *D, I]\n    x_whiten = torch.linalg.solve_triangular(\n        U.reshape(*shape, I, I),\n        x.unsqueeze(-1),\n        upper=True,\n    ).squeeze(-1)\n    return x_whiten\n</code></pre>"},{"location":"reference/functional/#cliffordlayers.nn.functional.groupnorm.clifford_group_norm","title":"<code>clifford_group_norm(x, n_blades, num_groups=1, running_mean=None, running_cov=None, weight=None, bias=None, training=True, momentum=0.1, eps=1e-05)</code>","text":"<p>Clifford group normalization</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>Tensor</code> <p>Input tensor of shape <code>(B, C, *D, I)</code> where I is the blade of the algebra.</p> required <code>n_blades</code> <code>int</code> <p>Number of blades of the Clifford algebra.</p> required <code>num_groups</code> <code>int</code> <p>Number of groups for which normalization is calculated. Defaults to 1.               For <code>num_groups == 1</code>, it effectively applies Clifford layer normalization, for <code>num_groups == C</code>, it effectively applies Clifford instance normalization.</p> <code>1</code> <code>running_mean</code> <code>Tensor</code> <p>The tensor with running mean statistics having shape <code>(I, C / num_groups)</code>. Defaults to None.</p> <code>None</code> <code>running_cov</code> <code>Tensor</code> <p>The tensor with running real-imaginary covariance statistics having shape <code>(I, I, C / num_groups)</code>. Defaults to None.</p> <code>None</code> <code>weight</code> <code>Union[Tensor, Parameter]</code> <p>Additional weight tensor which is applied post normalization, and has the shape <code>(I, I, C / num_groups)</code>. Defaults to None.</p> <code>None</code> <code>bias</code> <code>Union[Tensor, Parameter]</code> <p>Additional bias tensor which is applied post normalization, and has the shape <code>(I, C / num_groups)</code>. Defaults to None.</p> <code>None</code> <code>training</code> <code>bool</code> <p>Whether to use the running mean and variance. Defaults to True.</p> <code>True</code> <code>momentum</code> <code>float</code> <p>Momentum for the running mean and variance. Defaults to 0.1.</p> <code>0.1</code> <code>eps</code> <code>float</code> <p>Epsilon for the running mean and variance. Defaults to 1e-05.</p> <code>1e-05</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>Group normalized input of shape <code>(B, C, *D, I)</code>.</p> Source code in <code>cliffordlayers/nn/functional/groupnorm.py</code> <pre><code>def clifford_group_norm(\n    x: torch.Tensor,\n    n_blades: int,\n    num_groups: int = 1,\n    running_mean: Optional[torch.Tensor] = None,\n    running_cov: Optional[torch.Tensor] = None,\n    weight: Optional[Union[torch.Tensor, nn.Parameter]] = None,\n    bias: Optional[Union[torch.Tensor, nn.Parameter]] = None,\n    training: bool = True,\n    momentum: float = 0.1,\n    eps: float = 1e-05,\n) -&gt; torch.Tensor:\n    \"\"\"Clifford group normalization\n\n    Args:\n        x (torch.Tensor): Input tensor of shape `(B, C, *D, I)` where I is the blade of the algebra.\n\n        n_blades (int): Number of blades of the Clifford algebra.\n\n        num_groups (int): Number of groups for which normalization is calculated. Defaults to 1.\n                          For `num_groups == 1`, it effectively applies Clifford layer normalization, for `num_groups == C`, it effectively applies Clifford instance normalization.\n\n        running_mean (torch.Tensor, optional): The tensor with running mean statistics having shape `(I, C / num_groups)`. Defaults to None.\n        running_cov (torch.Tensor, optional): The tensor with running real-imaginary covariance statistics having shape `(I, I, C / num_groups)`. Defaults to None.\n\n        weight (Union[torch.Tensor, nn.Parameter], optional): Additional weight tensor which is applied post normalization, and has the shape `(I, I, C / num_groups)`. Defaults to None.\n\n        bias (Union[torch.Tensor, nn.Parameter], optional): Additional bias tensor which is applied post normalization, and has the shape `(I, C / num_groups)`. Defaults to None.\n\n        training (bool, optional): Whether to use the running mean and variance. Defaults to True.\n        momentum (float, optional): Momentum for the running mean and variance. Defaults to 0.1.\n        eps (float, optional): Epsilon for the running mean and variance. Defaults to 1e-05.\n\n    Returns:\n        (torch.Tensor): Group normalized input of shape `(B, C, *D, I)`.\n    \"\"\"\n\n    # Check arguments.\n    assert (running_mean is None and running_cov is None) or (running_mean is not None and running_cov is not None)\n    assert (weight is None and bias is None) or (weight is not None and bias is not None)\n\n    B, C, *D, I = x.shape\n    assert num_groups &lt;= C\n    assert C % num_groups == 0, \"Number of channels should be evenly divisible by the number of groups.\"\n    assert I == n_blades\n    if weight is not None and bias is not None:\n        # Check if weight and bias tensors are of correct shape.\n        assert weight.shape == (I, I, int(C / num_groups))\n        assert bias.shape == (I, int(C / num_groups))\n        weight = weight.repeat(1, 1, B)\n        bias = bias.repeat(1, B)\n\n    def _instance_norm(\n        x,\n        num_groups,\n        running_mean,\n        running_cov,\n        weight,\n        bias,\n        training,\n        momentum,\n        eps,\n    ):\n        if running_mean is not None and running_cov is not None:\n            assert running_mean.shape == (I, int(C / num_groups))\n            running_mean_orig = running_mean\n            running_mean = running_mean_orig.repeat(1, B)\n            assert running_cov.shape == (I, I, int(C / num_groups))\n            running_cov_orig = running_cov\n            running_cov = running_cov_orig.repeat(1, 1, B)\n\n        # Reshape such that batch normalization can be applied.\n        # For num_groups == 1, it defaults to layer normalization,\n        # for num_groups == C, it defaults to instance normalization.\n        x_reshaped = x.reshape(1, int(B * C / num_groups), num_groups, *D, I)\n\n        x_norm = clifford_batch_norm(\n            x_reshaped,\n            n_blades,\n            running_mean,\n            running_cov,\n            weight,\n            bias,\n            training,\n            momentum,\n            eps,\n        )\n\n        # Reshape back running mean and running var.\n        if running_mean is not None:\n            running_mean_orig.copy_(running_mean.view(I, B, int(C / num_groups)).mean(1, keepdim=False))\n        if running_cov is not None:\n            running_cov_orig.copy_(running_cov.view(I, I, B, int(C / num_groups)).mean(1, keepdim=False))\n\n        return x_norm.view(B, C, *D, I)\n\n    return _instance_norm(\n        x,\n        num_groups,\n        running_mean,\n        running_cov,\n        weight,\n        bias,\n        training,\n        momentum,\n        eps,\n    )\n</code></pre>"},{"location":"reference/functional/#cliffordlayers.nn.functional.groupnorm.complex_group_norm","title":"<code>complex_group_norm(x, num_groups=1, running_mean=None, running_cov=None, weight=None, bias=None, training=True, momentum=0.1, eps=1e-05)</code>","text":"<p>Group normalization for complex-valued tensors.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>Tensor</code> <p>The input complex-valued data is expected to be at least 2d, with               shape <code>(B, C, *D)</code>, where <code>B</code> is the batch dimension, <code>C</code> the               channels/features, and *D the remaining dimensions (if present).</p> required <code>num_groups</code> <code>int</code> <p>Number of groups for which normalization is calculated. Defaults to 1.               For <code>num_groups == 1</code>, it effectively applies complex-valued layer normalization;               for <code>num_groups == C</code>, it effectively applies complex-valued instance normalization.</p> <code>1</code> <code>running_mean</code> <code>Tensor</code> <p>The tensor with running mean statistics having shape <code>(2, C / num_groups)</code>. Defaults to None.</p> <code>None</code> <code>running_cov</code> <code>Tensor</code> <p>The tensor with running real-imaginary covariance statistics having shape <code>(2, 2, C / num_groups)</code>. Defaults to None.</p> <code>None</code> <code>weight</code> <code>Union[Tensor, Parameter]</code> <p>Additional weight tensor which is applied post normalization, and has the shape <code>(2, 2, C/ num_groups)</code>. Defaults to None.</p> <code>None</code> <code>bias</code> <code>Union[Tensor, Parameter]</code> <p>Additional bias tensor which is applied post normalization, and has the shape <code>(2, C / num_groups)</code>. Defaults to None.</p> <code>None</code> <code>training</code> <code>bool</code> <p>Whether to use the running mean and variance. Defaults to True.</p> <code>True</code> <code>momentum</code> <code>float</code> <p>Momentum for the running mean and variance. Defaults to 0.1.</p> <code>0.1</code> <code>eps</code> <code>float</code> <p>Epsilon for the running mean and variance. Defaults to 1e-05.</p> <code>1e-05</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>Normalized input as complex tensor of shape <code>(B, C, *D)</code>.</p> Source code in <code>cliffordlayers/nn/functional/groupnorm.py</code> <pre><code>def complex_group_norm(\n    x: torch.Tensor,\n    num_groups: int = 1,\n    running_mean: Optional[torch.Tensor] = None,\n    running_cov: Optional[torch.Tensor] = None,\n    weight: Optional[Union[torch.Tensor, nn.Parameter]] = None,\n    bias: Optional[Union[torch.Tensor, nn.Parameter]] = None,\n    training: bool = True,\n    momentum: float = 0.1,\n    eps: float = 1e-05,\n):\n    \"\"\"Group normalization for complex-valued tensors.\n\n    Args:\n        x (torch.Tensor): The input complex-valued data is expected to be at least 2d, with\n                          shape `(B, C, *D)`, where `B` is the batch dimension, `C` the\n                          channels/features, and *D the remaining dimensions (if present).\n\n        num_groups (int): Number of groups for which normalization is calculated. Defaults to 1.\n                          For `num_groups == 1`, it effectively applies complex-valued layer normalization;\n                          for `num_groups == C`, it effectively applies complex-valued instance normalization.\n\n        running_mean (torch.Tensor, optional): The tensor with running mean statistics having shape `(2, C / num_groups)`. Defaults to None.\n        running_cov (torch.Tensor, optional): The tensor with running real-imaginary covariance statistics having shape `(2, 2, C / num_groups)`. Defaults to None.\n\n        weight (Union[torch.Tensor, nn.Parameter], optional): Additional weight tensor which is applied post normalization, and has the shape `(2, 2, C/ num_groups)`. Defaults to None.\n\n        bias (Union[torch.Tensor, nn.Parameter], optional): Additional bias tensor which is applied post normalization, and has the shape `(2, C / num_groups)`. Defaults to None.\n\n        training (bool, optional): Whether to use the running mean and variance. Defaults to True.\n        momentum (float, optional): Momentum for the running mean and variance. Defaults to 0.1.\n        eps (float, optional): Epsilon for the running mean and variance. Defaults to 1e-05.\n\n    Returns:\n        (torch.Tensor): Normalized input as complex tensor of shape `(B, C, *D)`.\n    \"\"\"\n\n    # Check arguments.\n    assert (running_mean is None and running_cov is None) or (running_mean is not None and running_cov is not None)\n    assert (weight is None and bias is None) or (weight is not None and bias is not None)\n\n    B, C, *D = x.shape\n    assert C % num_groups == 0, \"Number of channels should be evenly divisible by the number of groups.\"\n    assert num_groups &lt;= C\n    if weight is not None and bias is not None:\n        # Check if weight and bias tensors are of correct shape.\n        assert weight.shape == (2, 2, int(C / num_groups))\n        assert bias.shape == (2, int(C / num_groups))\n        weight = weight.repeat(1, 1, B)\n        bias = bias.repeat(1, B)\n\n    def _instance_norm(\n        x,\n        num_groups,\n        running_mean,\n        running_cov,\n        weight,\n        bias,\n        training,\n        momentum,\n        eps,\n    ):\n        if running_mean is not None and running_cov is not None:\n            assert running_mean.shape == (2, int(C / num_groups))\n            running_mean_orig = running_mean\n            running_mean = running_mean_orig.repeat(1, B)\n            assert running_cov.shape == (2, 2, int(C / num_groups))\n            running_cov_orig = running_cov\n            running_cov = running_cov_orig.repeat(1, 1, B)\n\n        # Reshape such that batch normalization can be applied.\n        # For num_groups == 1, it defaults to layer normalization,\n        # for num_groups == C, it defaults to instance normalization.\n        x_reshaped = x.view(1, int(B * C / num_groups), num_groups, *D)\n\n        x_norm = complex_batch_norm(\n            x_reshaped,\n            running_mean,\n            running_cov,\n            weight=weight,\n            bias=bias,\n            training=training,\n            momentum=momentum,\n            eps=eps,\n        )\n\n        # Reshape back running mean and running var.\n        if running_mean is not None:\n            running_mean_orig.copy_(running_mean.view(2, B, int(C / num_groups)).mean(1, keepdim=False))\n        if running_cov is not None:\n            running_cov_orig.copy_(running_cov.view(2, 2, B, int(C / num_groups)).mean(2, keepdim=False))\n\n        return x_norm.view(B, C, *D)\n\n    return _instance_norm(\n        x,\n        num_groups,\n        running_mean,\n        running_cov,\n        weight=weight,\n        bias=bias,\n        training=training,\n        momentum=momentum,\n        eps=eps,\n    )\n</code></pre>"},{"location":"reference/misc/","title":"Clifford Kernels","text":"<p>We provide 1D, 2D, 3D Clifford kernels for different algebras. Additionally, we provide complex, quaternion, and octonion kernels -- those are specific instances of those kernels.</p>"},{"location":"reference/misc/#cliffordlayers.cliffordkernels.get_1d_clifford_kernel","title":"<code>get_1d_clifford_kernel(w, g)</code>","text":"<p>Clifford kernel for 1d Clifford algebras, g = [-1] corresponds to a complex number kernel.</p> <p>Parameters:</p> Name Type Description Default <code>w</code> <code>Union[tuple, list, Tensor, Parameter, ParameterList]</code> <p>Weight input of shape <code>(2, d~input~, d~output~, ...)</code>.</p> required <code>g</code> <code>Tensor</code> <p>Signature of Clifford algebra.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>Wrong encoding/decoding options provided.</p> <p>Returns:</p> Type Description <code>Tuple[int, Tensor]</code> <p>Number of output blades, weight output of shape <code>(d~output~ * 2, d~input~ * 2, ...)</code>.</p> Source code in <code>cliffordlayers/cliffordkernels.py</code> <pre><code>def get_1d_clifford_kernel(\n    w: Union[tuple, list, torch.Tensor, nn.Parameter, nn.ParameterList], g: torch.Tensor\n) -&gt; Tuple[int, torch.Tensor]:\n    \"\"\"Clifford kernel for 1d Clifford algebras, g = [-1] corresponds to a complex number kernel.\n\n    Args:\n        w (Union[tuple, list, torch.Tensor, nn.Parameter, nn.ParameterList]): Weight input of shape `(2, d~input~, d~output~, ...)`.\n        g (torch.Tensor): Signature of Clifford algebra.\n\n    Raises:\n        ValueError: Wrong encoding/decoding options provided.\n\n    Returns:\n        (Tuple[int, torch.Tensor]):  Number of output blades, weight output of shape `(d~output~ * 2, d~input~ * 2, ...)`.\n    \"\"\"\n    assert isinstance(g, torch.Tensor)\n    assert g.numel() == 1\n    w = _w_assert(w)\n    assert len(w) == 2\n\n    k0 = torch.cat([w[0], g[0] * w[1]], dim=1)\n    k1 = torch.cat([w[1], w[0]], dim=1)\n    k = torch.cat([k0, k1], dim=0)\n    return 2, k\n</code></pre>"},{"location":"reference/misc/#cliffordlayers.cliffordkernels.get_2d_clifford_kernel","title":"<code>get_2d_clifford_kernel(w, g)</code>","text":"<p>Clifford kernel for 2d Clifford algebras, g = [-1, -1] corresponds to a quaternion kernel.</p> <p>Parameters:</p> Name Type Description Default <code>w</code> <code>Union[tuple, list, Tensor, Parameter, ParameterList]</code> <p>Weight input of shape <code>(4, d~input~, d~output~, ...)</code>.</p> required <code>g</code> <code>Tensor</code> <p>Signature of Clifford algebra.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>Wrong encoding/decoding options provided.</p> <p>Returns:</p> Type Description <code>Tuple[int, Tensor]</code> <p>Number of output blades, weight output of shape <code>(d~output~ * 4, d~input~ * 4, ...)</code>.</p> Source code in <code>cliffordlayers/cliffordkernels.py</code> <pre><code>def get_2d_clifford_kernel(\n    w: Union[tuple, list, torch.Tensor, nn.Parameter, nn.ParameterList], g: torch.Tensor\n) -&gt; Tuple[int, torch.Tensor]:\n    \"\"\"Clifford kernel for 2d Clifford algebras, g = [-1, -1] corresponds to a quaternion kernel.\n\n    Args:\n        w (Union[tuple, list, torch.Tensor, nn.Parameter, nn.ParameterList]): Weight input of shape `(4, d~input~, d~output~, ...)`.\n        g (torch.Tensor): Signature of Clifford algebra.\n\n    Raises:\n        ValueError: Wrong encoding/decoding options provided.\n\n    Returns:\n        (Tuple[int, torch.Tensor]): Number of output blades, weight output of shape `(d~output~ * 4, d~input~ * 4, ...)`.\n    \"\"\"\n    assert isinstance(g, torch.Tensor)\n    assert g.numel() == 2\n    w = _w_assert(w)\n    assert len(w) == 4\n\n    k0 = torch.cat([w[0], g[0] * w[1], g[1] * w[2], -g[0] * g[1] * w[3]], dim=1)\n    k1 = torch.cat([w[1], w[0], -g[1] * w[3], g[1] * w[2]], dim=1)\n    k2 = torch.cat([w[2], g[0] * w[3], w[0], -g[0] * w[1]], dim=1)\n    k3 = torch.cat([w[3], w[2], -w[1], w[0]], dim=1)\n    k = torch.cat([k0, k1, k2, k3], dim=0)\n    return 4, k\n</code></pre>"},{"location":"reference/misc/#cliffordlayers.cliffordkernels.get_2d_clifford_rotation_kernel","title":"<code>get_2d_clifford_rotation_kernel(w, g)</code>","text":"<p>Rotational Clifford kernel for 2d Clifford algebras, the vector part corresponds to quaternion rotation.</p> <p>Parameters:</p> Name Type Description Default <code>w</code> <code>Union[tuple, list, Tensor, Parameter, ParameterList]</code> <p>Weight input of shape <code>(6, d~input~, d~output~, ...)</code>.         <code>w[0]</code>, <code>w[1]</code>, <code>w[2]</code>, <code>w[3]</code> are the 2D Clifford weight tensors;         <code>w[4]</code> is the scaling tensor; <code>w[5]</code> is the zero kernel tensor.</p> required <code>g</code> <code>Tensor</code> <p>Signature of Clifford algebra.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>Wrong encoding/decoding options provided.</p> <p>Returns:</p> Type Description <code>Tuple[int, Tensor]</code> <p>Number of output blades, weight output of shape <code>(d~output~ * 4, d~input~ * 4, ...)</code>.</p> Source code in <code>cliffordlayers/cliffordkernels.py</code> <pre><code>def get_2d_clifford_rotation_kernel(\n    w: Union[tuple, list, torch.Tensor, nn.Parameter, nn.ParameterList], g: torch.Tensor\n) -&gt; Tuple[int, torch.Tensor]:\n    \"\"\"Rotational Clifford kernel for 2d Clifford algebras, the vector part corresponds to quaternion rotation.\n\n    Args:\n        w (Union[tuple, list, torch.Tensor, nn.Parameter, nn.ParameterList]): Weight input of shape `(6, d~input~, d~output~, ...)`.\n                    `w[0]`, `w[1]`, `w[2]`, `w[3]` are the 2D Clifford weight tensors;\n                    `w[4]` is the scaling tensor; `w[5]` is the zero kernel tensor.\n\n        g (torch.Tensor): Signature of Clifford algebra.\n\n    Raises:\n        ValueError: Wrong encoding/decoding options provided.\n\n    Returns:\n        (Tuple[int, torch.Tensor]): Number of output blades, weight output of shape `(d~output~ * 4, d~input~ * 4, ...)`.\n    \"\"\"\n    assert isinstance(g, torch.Tensor)\n    assert g.numel() == 2\n    assert g[0] == -1 and g[1] == -1, \"Wrong signature of Clifford algebra. Signature not suitable for rotation kernel.\"\n    w = _w_assert(w)\n    assert len(w) == 6\n\n    # Adding scalar output kernel.\n    k0 = torch.cat([w[0], -w[1], -w[2], -w[3]], dim=1)\n\n    # Rotational kernel from here onwards.\n    s0 = w[0] * w[0]\n    s1 = w[1] * w[1]\n    s2 = w[2] * w[2]\n    s3 = w[3] * w[3]\n    norm = torch.sqrt(s0 + s1 + s2 + s3 + 0.0001)\n    w0_n = w[0] / norm\n    w1_n = w[1] / norm\n    w2_n = w[2] / norm\n    w3_n = w[3] / norm\n\n    norm_factor = 2.0\n    s1 = norm_factor * (w1_n * w1_n)\n    s2 = norm_factor * (w2_n * w2_n)\n    s3 = norm_factor * (w3_n * w3_n)\n    rot01 = norm_factor * w0_n * w1_n\n    rot02 = norm_factor * w0_n * w2_n\n    rot03 = norm_factor * w0_n * w3_n\n    rot12 = norm_factor * w1_n * w2_n\n    rot13 = norm_factor * w1_n * w3_n\n    rot23 = norm_factor * w2_n * w3_n\n\n    scale = w[4]\n    zero_kernel = w[5]\n\n    k1 = torch.cat(\n        [\n            zero_kernel,\n            scale * (1.0 - (s2 + s3)),\n            scale * (rot12 - rot03),\n            scale * (rot13 + rot02),\n        ],\n        dim=1,\n    )\n    k2 = torch.cat(\n        [\n            zero_kernel,\n            scale * (rot12 + rot03),\n            scale * (1.0 - (s1 + s3)),\n            scale * (rot23 - rot01),\n        ],\n        dim=1,\n    )\n    k3 = torch.cat(\n        [\n            zero_kernel,\n            scale * (rot13 - rot02),\n            scale * (rot23 + rot01),\n            scale * (1.0 - (s1 + s2)),\n        ],\n        dim=1,\n    )\n    k = torch.cat([k0, k1, k2, k3], dim=0)\n    return 4, k\n</code></pre>"},{"location":"reference/misc/#cliffordlayers.cliffordkernels.get_3d_clifford_kernel","title":"<code>get_3d_clifford_kernel(w, g)</code>","text":"<p>Clifford kernel for 3d Clifford algebras, g = [-1, -1, -1] corresponds to an octonion kernel.</p> <p>Parameters:</p> Name Type Description Default <code>w</code> <code>Union[tuple, list, Tensor, Parameter, ParameterList]</code> <p>Weight input of shape <code>(8, d~input~, d~output~, ...)</code>.</p> required <code>g</code> <code>Tensor</code> <p>Signature of Clifford algebra.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>Wrong encoding/decoding options provided.</p> <p>Returns:</p> Type Description <code>Tuple[int, Tensor]</code> <p>Number of output blades, weight output of dimension <code>(d~output~ * 8, d~input~ * 8, ...)</code>.</p> Source code in <code>cliffordlayers/cliffordkernels.py</code> <pre><code>def get_3d_clifford_kernel(\n    w: Union[tuple, list, torch.Tensor, nn.Parameter, nn.ParameterList], g: torch.Tensor\n) -&gt; Tuple[int, torch.Tensor]:\n    \"\"\"Clifford kernel for 3d Clifford algebras, g = [-1, -1, -1] corresponds to an octonion kernel.\n\n    Args:\n        w (Union[tuple, list, torch.Tensor, nn.Parameter, nn.ParameterList]): Weight input of shape `(8, d~input~, d~output~, ...)`.\n        g (torch.Tensor): Signature of Clifford algebra.\n\n    Raises:\n        ValueError: Wrong encoding/decoding options provided.\n\n    Returns:\n        (Tuple[int, torch.Tensor]): Number of output blades, weight output of dimension `(d~output~ * 8, d~input~ * 8, ...)`.\n    \"\"\"\n    assert isinstance(g, torch.Tensor)\n    assert g.numel() == 3\n    w = _w_assert(w)\n    assert len(w) == 8\n\n    k0 = torch.cat(\n        [\n            w[0],\n            w[1] * g[0],\n            w[2] * g[1],\n            w[3] * g[2],\n            -w[4] * g[0] * g[1],\n            -w[5] * g[0] * g[2],\n            -w[6] * g[1] * g[2],\n            -w[7] * g[0] * g[1] * g[2],\n        ],\n        dim=1,\n    )\n    k1 = torch.cat(\n        [w[1], w[0], -w[4] * g[1], -w[5] * g[2], w[2] * g[1], w[3] * g[2], -w[7] * g[1] * g[2], -w[6] * g[2] * g[1]],\n        dim=1,\n    )\n    k2 = torch.cat(\n        [w[2], w[4] * g[0], w[0], -w[6] * g[2], -w[1] * g[0], w[7] * g[0] * g[2], w[3] * g[2], w[5] * g[2] * g[0]],\n        dim=1,\n    )\n    k3 = torch.cat(\n        [w[3], w[5] * g[0], w[6] * g[1], w[0], -w[7] * g[0] * g[1], -w[1] * g[0], -w[2] * g[1], -w[4] * g[0] * g[1]],\n        dim=1,\n    )\n    k4 = torch.cat([w[4], w[2], -w[1], g[2] * w[7], w[0], -w[6] * g[2], w[5] * g[2], w[3] * g[2]], dim=1)\n    k5 = torch.cat([w[5], w[3], -w[7] * g[1], -w[1], w[6] * g[1], w[0], -w[4] * g[1], -w[2] * g[1]], dim=1)\n    k6 = torch.cat([w[6], w[7] * g[0], w[3], -w[2], -w[5] * g[0], w[4] * g[0], w[0], w[1] * g[0]], dim=1)\n    k7 = torch.cat([w[7], w[6], -w[5], w[4], w[3], -w[2], w[1], w[0]], dim=1)\n    k = torch.cat([k0, k1, k2, k3, k4, k5, k6, k7], dim=0)\n    return 8, k\n</code></pre>"},{"location":"reference/misc/#cliffordlayers.cliffordkernels.get_complex_kernel","title":"<code>get_complex_kernel(w)</code>","text":"<p>Complex kernel.</p> <p>Parameters:</p> Name Type Description Default <code>w</code> <code>Union[tuple, list, Tensor, Parameter, ParameterList]</code> <p>Weight input of shape <code>(2, d~input~, d~output~, ...)</code>.</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>Weight output of shape <code>(d~output~ * 2, d~input~ * 2, ...)</code>.</p> Source code in <code>cliffordlayers/cliffordkernels.py</code> <pre><code>def get_complex_kernel(w: Union[tuple, list, torch.Tensor, nn.Parameter, nn.ParameterList]) -&gt; torch.Tensor:\n    \"\"\"Complex kernel.\n\n    Args:\n        w (Union[tuple, list, torch.Tensor, nn.Parameter, nn.ParameterList]): Weight input of shape `(2, d~input~, d~output~, ...)`.\n\n    Returns:\n        (torch.Tensor):  Weight output of shape `(d~output~ * 2, d~input~ * 2, ...)`.\n    \"\"\"\n    w = _w_assert(w)\n    assert len(w) == 2\n    k0 = torch.cat([w[0], -w[1]], dim=1)\n    k1 = torch.cat([w[1], w[0]], dim=1)\n    k = torch.cat([k0, k1], dim=0)\n    return k\n</code></pre>"},{"location":"reference/misc/#cliffordlayers.cliffordkernels.get_octonion_kernel","title":"<code>get_octonion_kernel(w)</code>","text":"<p>Octonion kernels.</p> <p>Parameters:</p> Name Type Description Default <code>w</code> <code>Union[tuple, list, Tensor, Parameter, ParameterList]</code> <p>Weight input of shape <code>(8, d~input~, d~output~, ...)</code>.</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>Weight output of shape <code>(d~output~ * 8, d~input~ * 8, ...)</code>.</p> Source code in <code>cliffordlayers/cliffordkernels.py</code> <pre><code>def get_octonion_kernel(w: Union[tuple, list, torch.Tensor, nn.Parameter, nn.ParameterList]) -&gt; torch.Tensor:\n    \"\"\"Octonion kernels.\n\n    Args:\n        w (Union[tuple, list, torch.Tensor, nn.Parameter, nn.ParameterList]): Weight input of shape `(8, d~input~, d~output~, ...)`.\n\n\n    Returns:\n        (torch.Tensor):  Weight output of shape `(d~output~ * 8, d~input~ * 8, ...)`.\n    \"\"\"\n    w = _w_assert(w)\n    assert len(w) == 8\n    k0 = torch.cat([w[0], -w[1], -w[2], -w[3], -w[4], -w[5], -w[6], w[7]], dim=1)\n    k1 = torch.cat([w[1], w[0], w[4], w[5], -w[2], -w[3], -w[7], -w[6]], dim=1)\n    k2 = torch.cat([w[2], -w[4], w[0], w[6], w[1], w[7], -w[3], w[5]], dim=1)\n    k3 = torch.cat([w[3], -w[5], -w[6], w[0], -w[7], w[1], w[2], -w[4]], dim=1)\n    k4 = torch.cat([w[4], w[2], -w[1], -w[7], w[0], w[6], -w[5], -w[3]], dim=1)\n    k5 = torch.cat([w[5], w[3], w[7], -w[1], -w[6], w[0], w[4], w[2]], dim=1)\n    k6 = torch.cat([w[6], -w[7], w[3], -w[2], w[5], -w[4], w[0], -w[1]], dim=1)\n    k7 = torch.cat([w[7], w[6], -w[5], w[4], w[3], -w[2], w[1], w[0]], dim=1)\n    k = torch.cat([k0, k1, k2, k3, k4, k5, k6, k7], dim=0)\n    return k\n</code></pre>"},{"location":"reference/misc/#cliffordlayers.cliffordkernels.get_quaternion_kernel","title":"<code>get_quaternion_kernel(w)</code>","text":"<p>Quaternion kernel.</p> <p>Parameters:</p> Name Type Description Default <code>w</code> <code>Union[tuple, list, Tensor, Parameter, ParameterList]</code> <p>Weight input of shape <code>(4, d~input~, d~output~, ...)</code>.</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>Weight output of shape <code>(d~output~ * 4, d~input~ * 4, ...)</code>.</p> Source code in <code>cliffordlayers/cliffordkernels.py</code> <pre><code>def get_quaternion_kernel(w: Union[tuple, list, torch.Tensor, nn.Parameter, nn.ParameterList]) -&gt; torch.Tensor:\n    \"\"\"Quaternion kernel.\n\n    Args:\n        w (Union[tuple, list, torch.Tensor, nn.Parameter, nn.ParameterList]): Weight input of shape `(4, d~input~, d~output~, ...)`.\n\n\n    Returns:\n        (torch.Tensor):  Weight output of shape `(d~output~ * 4, d~input~ * 4, ...)`.\n    \"\"\"\n    w = _w_assert(w)\n    assert len(w) == 4\n    k0 = torch.cat([w[0], -w[1], -w[2], -w[3]], dim=1)\n    k1 = torch.cat([w[1], w[0], w[3], -w[2]], dim=1)\n    k2 = torch.cat([w[2], -w[3], w[0], w[1]], dim=1)\n    k3 = torch.cat([w[3], w[2], -w[1], w[0]], dim=1)\n    k = torch.cat([k0, k1, k2, k3], dim=0)\n    return k\n</code></pre>"},{"location":"reference/misc/#cliffordlayers.cliffordkernels.get_quaternion_rotation_kernel","title":"<code>get_quaternion_rotation_kernel(w)</code>","text":"<p>Quaternion rotation, taken mostly from https://github.com/Orkis-Research/Pytorch-Quaternion-Neural-Networks</p> <p>Parameters:</p> Name Type Description Default <code>w</code> <code>Union[tuple, list, Tensor, Parameter, ParameterList]</code> <p>Weight input of shape <code>(6, d~input~, d~output~, ...)</code>.         <code>w[0]</code>, <code>w[1]</code>, <code>w[2]</code>, <code>w[3]</code> are the quaternion w;         tensors; <code>w[4]</code> is the scaling tensor; <code>w[5]</code> is the zero kernel tensor.</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>Quaternion weight output of dimension <code>(d~output * 3, d~input * 4, ...)</code>.</p> Source code in <code>cliffordlayers/cliffordkernels.py</code> <pre><code>def get_quaternion_rotation_kernel(w: Union[tuple, list, torch.Tensor, nn.Parameter, nn.ParameterList]) -&gt; torch.Tensor:\n    \"\"\"Quaternion rotation, taken mostly from &lt;https://github.com/Orkis-Research/Pytorch-Quaternion-Neural-Networks&gt;\n\n    Args:\n        w (Union[tuple, list, torch.Tensor, nn.Parameter, nn.ParameterList]): Weight input of shape `(6, d~input~, d~output~, ...)`.\n                    `w[0]`, `w[1]`, `w[2]`, `w[3]` are the quaternion w;\n                    tensors; `w[4]` is the scaling tensor; `w[5]` is the zero kernel tensor.\n\n    Returns:\n        (torch.Tensor): Quaternion weight output of dimension `(d~output * 3, d~input * 4, ...)`.\n    \"\"\"\n    w = _w_assert(w)\n    assert len(w) == 6\n    square_1 = w[0] * w[0]\n    square_2 = w[1] * w[1]\n    square_3 = w[2] * w[2]\n    square_4 = w[3] * w[3]\n\n    norm = torch.sqrt(square_1 + square_2 + square_3 + square_4 + 0.0001)\n\n    w1_n = w[0] / norm\n    w2_n = w[1] / norm\n    w3_n = w[2] / norm\n    w4_n = w[3] / norm\n\n    norm_factor = 2.0\n    square_2 = norm_factor * (w2_n * w2_n)\n    square_3 = norm_factor * (w3_n * w3_n)\n    square_4 = norm_factor * (w4_n * w4_n)\n\n    rot12 = norm_factor * w1_n * w2_n\n    rot13 = norm_factor * w1_n * w3_n\n    rot14 = norm_factor * w1_n * w4_n\n    rot23 = norm_factor * w2_n * w3_n\n    rot24 = norm_factor * w2_n * w4_n\n    rot34 = norm_factor * w3_n * w4_n\n\n    scale = w[4]\n    zero_kernel = w[5]\n\n    rot_kernel2 = torch.cat(\n        [\n            zero_kernel,\n            scale * (1.0 - (square_3 + square_4)),\n            scale * (rot23 - rot14),\n            scale * (rot24 + rot13),\n        ],\n        dim=1,\n    )\n    rot_kernel3 = torch.cat(\n        [\n            zero_kernel,\n            scale * (rot23 + rot14),\n            scale * (1.0 - (square_2 + square_4)),\n            scale * (rot34 - rot12),\n        ],\n        dim=1,\n    )\n    rot_kernel4 = torch.cat(\n        [\n            zero_kernel,\n            scale * (rot24 - rot13),\n            scale * (rot34 + rot12),\n            scale * (1.0 - (square_2 + square_3)),\n        ],\n        dim=1,\n    )\n\n    k = torch.cat([rot_kernel2, rot_kernel3, rot_kernel4], dim=0)\n    return k\n</code></pre>"},{"location":"reference/models/","title":"Clifford models","text":"<p>We provide exemplary 2D and 3D Clifford models as used in the paper.</p> <p>All these modules are available for different algebras.</p>"},{"location":"reference/models/#2d-models","title":"2D models","text":"<p>The following code snippet initializes a 2D Clifford ResNet.</p> <pre><code>import torch.nn.functional as F\n\nfrom cliffordlayers.models.basic.twod import (\n    CliffordFluidNet2d,\n    CliffordBasicBlock2d,\n)\n\nmodel = CliffordFluidNet2d(\n        g = [-1, -1],\n        block = CliffordBasicBlock2d,\n        num_blocks = [2, 2, 2, 2],\n        in_channels = in_channels,\n        out_channels = out_channels,\n        hidden_channels = 32,\n        activation = F.gelu,\n        norm = True,\n        rotation = False,\n    )\n</code></pre> <p>The following code snippet initializes a 2D rotational Clifford ResNet.</p> <pre><code>import torch.nn.functional as F\n\nfrom cliffordlayers.models.basic.twod import (\n    CliffordFluidNet2d,\n    CliffordBasicBlock2d,\n)\n\nmodel = CliffordNet2d(\n        g = [-1, -1],\n        block = CliffordBasicBlock2d,\n        num_blocks = [2, 2, 2, 2],\n        in_channels = in_channels,\n        out_channels = out_channels,\n        hidden_channels = 32,\n        activation = F.gelu,\n        norm = True,\n        rotation = True,\n    )\n</code></pre> <p>The following code snippet initializes a 2D Clifford FNO.</p> <pre><code>import torch.nn.functional as F\n\nfrom cliffordlayers.models.utils import partialclass\nfrom cliffordlayers.models.basic.twod import (\n    CliffordFluidNet2d,\n    CliffordFourierBasicBlock2d,\n)\n\nmodel = CliffordFluidNet2d(\n        g = [-1, -1],\n        block = partialclass(\n                \"CliffordFourierBasicBlock2d\", CliffordFourierBasicBlock2d, modes1=32, modes2=32\n            ),\n        num_blocks = [1, 1, 1, 1],\n        in_channels = in_channels,\n        out_channels = out_channels,\n        hidden_channels = 32,\n        activation = F.gelu,\n        norm = False,\n        rotation = False,\n    )\n</code></pre>"},{"location":"reference/models/#cliffordlayers.models.basic.twod.CliffordBasicBlock2d","title":"<code>CliffordBasicBlock2d</code>","text":"<p>             Bases: <code>Module</code></p> <p>2D building block for Clifford ResNet architectures.</p> <p>Parameters:</p> Name Type Description Default <code>g</code> <code>Union[tuple, list, Tensor]</code> <p>Signature of Clifford algebra.</p> required <code>in_channels</code> <code>int</code> <p>Number of input channels.</p> required <code>out_channels</code> <code>int</code> <p>Number of output channels.</p> required <code>activation</code> <code>Callable</code> <p>Activation function. Defaults to F.gelu.</p> <code>gelu</code> <code>kernel_size</code> <code>int</code> <p>Kernel size of Clifford convolution. Defaults to 3.</p> <code>3</code> <code>stride</code> <code>int</code> <p>Stride of Clifford convolution. Defaults to 1.</p> <code>1</code> <code>padding</code> <code>int</code> <p>Padding of Clifford convolution. Defaults to 1.</p> <code>1</code> <code>rotation</code> <code>bool</code> <p>Wether to use rotational Clifford convolution. Defaults to False.</p> <code>False</code> <code>norm</code> <code>bool</code> <p>Wether to use Clifford (group) normalization. Defaults to False.</p> <code>False</code> <code>num_groups</code> <code>int</code> <p>Number of groups when using Clifford (group) normalization. Defaults to 1.</p> <code>1</code> Source code in <code>cliffordlayers/models/basic/twod.py</code> <pre><code>class CliffordBasicBlock2d(nn.Module):\n    \"\"\"2D building block for Clifford ResNet architectures.\n\n    Args:\n        g (Union[tuple, list, torch.Tensor]): Signature of Clifford algebra.\n        in_channels (int): Number of input channels.\n        out_channels (int): Number of output channels.\n        activation (Callable, optional): Activation function. Defaults to F.gelu.\n        kernel_size (int, optional): Kernel size of Clifford convolution. Defaults to 3.\n        stride (int, optional): Stride of Clifford convolution. Defaults to 1.\n        padding (int, optional): Padding of Clifford convolution. Defaults to 1.\n        rotation (bool, optional): Wether to use rotational Clifford convolution. Defaults to False.\n        norm (bool, optional): Wether to use Clifford (group) normalization. Defaults to False.\n        num_groups (int, optional): Number of groups when using Clifford (group) normalization. Defaults to 1.\n    \"\"\"\n\n    expansion: int = 1\n\n    def __init__(\n        self,\n        g: Union[tuple, list, torch.Tensor],\n        in_channels: int,\n        out_channels: int,\n        activation: Callable = F.gelu,\n        kernel_size: int = 3,\n        stride: int = 1,\n        padding: int = 1,\n        rotation: bool = False,\n        norm: bool = False,\n        num_groups: int = 1,\n    ) -&gt; None:\n        super().__init__()\n        self.conv1 = CliffordConv2d(\n            g,\n            in_channels,\n            out_channels,\n            kernel_size=kernel_size,\n            stride=stride,\n            padding=padding,\n            bias=True,\n            rotation=rotation,\n        )\n        self.conv2 = CliffordConv2d(\n            g,\n            out_channels,\n            out_channels,\n            kernel_size=kernel_size,\n            stride=stride,\n            padding=padding,\n            bias=True,\n            rotation=rotation,\n        )\n        self.norm1 = CliffordGroupNorm2d(g, num_groups, in_channels) if norm else nn.Identity()\n        self.norm2 = CliffordGroupNorm2d(g, num_groups, out_channels) if norm else nn.Identity()\n        self.activation = activation\n\n    def __repr__(self):\n        return \"CliffordBasicBlock2d\"\n\n    def forward(self, x: torch.Tensor) -&gt; torch.Tensor:\n        out = self.conv1(self.activation(self.norm1(x)))\n        out = self.conv2(self.activation(self.norm2(out)))\n        return out + x\n</code></pre>"},{"location":"reference/models/#cliffordlayers.models.basic.twod.CliffordFluidNet2d","title":"<code>CliffordFluidNet2d</code>","text":"<p>             Bases: <code>Module</code></p> <p>2D building block for Clifford architectures for fluid mechanics (vector field+scalar field) with ResNet backbone network. The backbone networks follows these three steps:     1. Clifford scalar+vector field encoding.     2. Basic blocks as provided.     3. Clifford scalar+vector field decoding.</p> <p>Parameters:</p> Name Type Description Default <code>g</code> <code>Union[tuple, list, Tensor]</code> <p>Signature of Clifford algebra.</p> required <code>block</code> <code>Module</code> <p>Choice of basic blocks.</p> required <code>num_blocks</code> <code>list</code> <p>List of basic blocks in each residual block.</p> required <code>in_channels</code> <code>int</code> <p>Number of input channels.</p> required <code>out_channels</code> <code>int</code> <p>Number of output channels.</p> required <code>activation</code> <code>Callable</code> <p>Activation function. Defaults to F.gelu.</p> required <code>rotation</code> <code>bool</code> <p>Wether to use rotational Clifford convolution. Defaults to False.</p> required <code>norm</code> <code>bool</code> <p>Wether to use Clifford (group) normalization. Defaults to False.</p> <code>False</code> <code>num_groups</code> <code>int</code> <p>Number of groups when using Clifford (group) normalization. Defaults to 1.</p> <code>1</code> Source code in <code>cliffordlayers/models/basic/twod.py</code> <pre><code>class CliffordFluidNet2d(nn.Module):\n    \"\"\"2D building block for Clifford architectures for fluid mechanics (vector field+scalar field)\n    with ResNet backbone network. The backbone networks follows these three steps:\n        1. Clifford scalar+vector field encoding.\n        2. Basic blocks as provided.\n        3. Clifford scalar+vector field decoding.\n\n    Args:\n        g (Union[tuple, list, torch.Tensor]): Signature of Clifford algebra.\n        block (nn.Module): Choice of basic blocks.\n        num_blocks (list): List of basic blocks in each residual block.\n        in_channels (int): Number of input channels.\n        out_channels (int): Number of output channels.\n        activation (Callable, optional): Activation function. Defaults to F.gelu.\n        rotation (bool, optional): Wether to use rotational Clifford convolution. Defaults to False.\n        norm (bool, optional): Wether to use Clifford (group) normalization. Defaults to False.\n        num_groups (int, optional): Number of groups when using Clifford (group) normalization. Defaults to 1.\n    \"\"\"\n\n    # For periodic boundary conditions, set padding = 0.\n    padding = 9\n\n    def __init__(\n        self,\n        g: Union[tuple, list, torch.Tensor],\n        block: nn.Module,\n        num_blocks: list,\n        in_channels: int,\n        out_channels: int,\n        hidden_channels: int,\n        activation: Callable,\n        rotation: False,\n        norm: bool = False,\n        num_groups: int = 1,\n    ):\n        super().__init__()\n\n        self.activation = activation\n        # Encoding and decoding layers\n        self.encoder = CliffordConv2dScalarVectorEncoder(\n            g,\n            in_channels=in_channels,\n            out_channels=hidden_channels,\n            kernel_size=1,\n            padding=0,\n            rotation=rotation,\n        )\n        self.decoder = CliffordConv2dScalarVectorDecoder(\n            g,\n            in_channels=hidden_channels,\n            out_channels=out_channels,\n            kernel_size=1,\n            padding=0,\n            rotation=rotation,\n        )\n\n        # Residual blocks\n        self.layers = nn.ModuleList(\n            [\n                self._make_basic_block(\n                    g,\n                    block,\n                    hidden_channels,\n                    num_blocks[i],\n                    activation=activation,\n                    rotation=rotation,\n                    norm=norm,\n                    num_groups=num_groups,\n                )\n                for i in range(len(num_blocks))\n            ]\n        )\n\n    def _make_basic_block(\n        self,\n        g,\n        block: nn.Module,\n        hidden_channels: int,\n        num_blocks: int,\n        activation: Callable,\n        rotation: bool,\n        norm: bool,\n        num_groups: int,\n    ) -&gt; nn.Sequential:\n        blocks = []\n        for _ in range(num_blocks):\n            blocks.append(\n                block(\n                    g,\n                    hidden_channels,\n                    hidden_channels,\n                    activation=activation,\n                    rotation=rotation,\n                    norm=norm,\n                    num_groups=num_groups,\n                )\n            )\n        return nn.Sequential(*blocks)\n\n    def forward(self, x: torch.Tensor) -&gt; torch.Tensor:\n        assert x.dim() == 5\n\n        # Encoding layer\n        x = self.encoder(self.activation(x))\n\n        # Embed for non-periodic boundaries\n        if self.padding &gt; 0:\n            B_dim, C_dim, *D_dims, I_dim = range(len(x.shape))\n            x = x.permute(B_dim, I_dim, C_dim, *D_dims)\n            x = F.pad(x, [0, self.padding, 0, self.padding])\n            B_dim, I_dim, C_dim, *D_dims = range(len(x.shape))\n            x = x.permute(B_dim, C_dim, *D_dims, I_dim)\n\n        # Apply residual layers\n        for layer in self.layers:\n            x = layer(x)\n\n        # Decoding layer\n        if self.padding &gt; 0:\n            B_dim, C_dim, *D_dims, I_dim = range(len(x.shape))\n            x = x.permute(B_dim, I_dim, C_dim, *D_dims)\n            x = x[..., : -self.padding, : -self.padding]\n            B_dim, I_dim, C_dim, *D_dims = range(len(x.shape))\n            x = x.permute(B_dim, C_dim, *D_dims, I_dim)\n\n        # Output layer\n        x = self.decoder(x)\n        return x\n</code></pre>"},{"location":"reference/models/#cliffordlayers.models.basic.twod.CliffordFourierBasicBlock2d","title":"<code>CliffordFourierBasicBlock2d</code>","text":"<p>             Bases: <code>Module</code></p> <p>2D building block for Clifford FNO architectures.</p> <p>Parameters:</p> Name Type Description Default <code>g</code> <code>Union[tuple, list, Tensor]</code> <p>Signature of Clifford algebra.</p> required <code>in_channels</code> <code>int</code> <p>Number of input channels.</p> required <code>out_channels</code> <code>int</code> <p>Number of output channels.</p> required <code>activation</code> <code>Callable</code> <p>Activation function. Defaults to F.gelu.</p> <code>gelu</code> <code>kernel_size</code> <code>int</code> <p>Kernel size of Clifford convolution. Defaults to 3.</p> <code>1</code> <code>stride</code> <code>int</code> <p>Stride of Clifford convolution. Defaults to 1.</p> <code>1</code> <code>padding</code> <code>int</code> <p>Padding of Clifford convolution. Defaults to 1.</p> <code>0</code> <code>rotation</code> <code>bool</code> <p>Wether to use rotational Clifford convolution. Defaults to False.</p> <code>False</code> <code>norm</code> <code>bool</code> <p>Wether to use Clifford (group) normalization. Defaults to False.</p> <code>False</code> <code>num_groups</code> <code>int</code> <p>Number of groups when using Clifford (group) normalization. Defaults to 1.</p> <code>1</code> <code>modes1</code> <code>int</code> <p>Number of Fourier modes in the first dimension. Defaults to 16.</p> <code>16</code> <code>modes2</code> <code>int</code> <p>Number of Fourier modes in the second dimension. Defaults to 16.</p> <code>16</code> Source code in <code>cliffordlayers/models/basic/twod.py</code> <pre><code>class CliffordFourierBasicBlock2d(nn.Module):\n    \"\"\"2D building block for Clifford FNO architectures.\n\n    Args:\n        g (Union[tuple, list, torch.Tensor]): Signature of Clifford algebra.\n        in_channels (int): Number of input channels.\n        out_channels (int): Number of output channels.\n        activation (Callable, optional): Activation function. Defaults to F.gelu.\n        kernel_size (int, optional): Kernel size of Clifford convolution. Defaults to 3.\n        stride (int, optional): Stride of Clifford convolution. Defaults to 1.\n        padding (int, optional): Padding of Clifford convolution. Defaults to 1.\n        rotation (bool, optional): Wether to use rotational Clifford convolution. Defaults to False.\n        norm (bool, optional): Wether to use Clifford (group) normalization. Defaults to False.\n        num_groups (int, optional): Number of groups when using Clifford (group) normalization. Defaults to 1.\n        modes1 (int, optional): Number of Fourier modes in the first dimension. Defaults to 16.\n        modes2 (int, optional): Number of Fourier modes in the second dimension. Defaults to 16.\n    \"\"\"\n\n    expansion: int = 1\n\n    def __init__(\n        self,\n        g: Union[tuple, list, torch.Tensor],\n        in_channels: int,\n        out_channels: int,\n        activation: Callable = F.gelu,\n        kernel_size: int = 1,\n        stride: int = 1,\n        padding: int = 0,\n        rotation: bool = False,\n        norm: bool = False,\n        num_groups: int = 1,\n        modes1: int = 16,\n        modes2: int = 16,\n    ):\n        super().__init__()\n        self.fourier = CliffordSpectralConv2d(\n            g,\n            in_channels,\n            out_channels,\n            modes1=modes1,\n            modes2=modes2,\n        )\n        self.conv = CliffordConv2d(\n            g,\n            in_channels,\n            out_channels,\n            kernel_size=kernel_size,\n            stride=stride,\n            padding=padding,\n            bias=True,\n            rotation=rotation,\n        )\n        self.norm = CliffordGroupNorm2d(g, num_groups, out_channels) if norm else nn.Identity()\n        self.activation = activation\n\n    def __repr__(self):\n        return \"CliffordFourierBasicBlock2d\"\n\n    def forward(self, x: torch.Tensor) -&gt; torch.Tensor:\n        x1 = self.fourier(x)\n        x2 = self.conv(x)\n        return self.activation(self.norm(x1 + x2))\n</code></pre>"},{"location":"reference/models/#cliffordlayers.models.gca.twod.CliffordG3BasicBlock2d","title":"<code>CliffordG3BasicBlock2d</code>","text":"<p>             Bases: <code>Module</code></p> <p>Basic block for G3 convolutions on 2D grids, comprising two G3 Clifford convolutional layers.</p> <p>Parameters:</p> Name Type Description Default <code>in_channels</code> <code>int</code> <p>Number of input channels.</p> required <code>out_channels</code> <code>int</code> <p>Number of output channels.</p> required <code>kernel_size</code> <code>int</code> <p>Size of the convolutional kernel. Defaults to 3.</p> <code>3</code> <code>stride</code> <code>int</code> <p>Stride of the convolution operation. Defaults to 1.</p> <code>1</code> <code>padding</code> <code>int</code> <p>Padding added to both sides of the input. Defaults to 1.</p> <code>1</code> <code>activation</code> <code>str</code> <p>Type of activation function. Defaults to \"vlin\".</p> <code>'vlin'</code> <code>norm</code> <code>bool</code> <p>If True, normalization is applied. Defaults to True.</p> <code>True</code> <code>num_groups</code> <code>int</code> <p>Number of groups for the group normalization. Defaults to 1.</p> <code>1</code> <code>prenorm</code> <code>bool</code> <p>If True, normalization is applied before activation, otherwise after. Defaults to True.</p> <code>True</code> Source code in <code>cliffordlayers/models/gca/twod.py</code> <pre><code>class CliffordG3BasicBlock2d(nn.Module):\n    \"\"\"\n    Basic block for G3 convolutions on 2D grids, comprising two G3 Clifford convolutional layers.\n\n    Args:\n        in_channels (int): Number of input channels.\n        out_channels (int): Number of output channels.\n        kernel_size (int, optional): Size of the convolutional kernel. Defaults to 3.\n        stride (int, optional): Stride of the convolution operation. Defaults to 1.\n        padding (int, optional): Padding added to both sides of the input. Defaults to 1.\n        activation (str, optional): Type of activation function. Defaults to \"vlin\".\n        norm (bool, optional): If True, normalization is applied. Defaults to True.\n        num_groups (int, optional): Number of groups for the group normalization. Defaults to 1.\n        prenorm (bool, optional): If True, normalization is applied before activation, otherwise after. Defaults to True.\n    \"\"\"\n\n    expansion: int = 1\n\n    def __init__(\n        self,\n        in_channels: int,\n        out_channels: int,\n        kernel_size: int = 3,\n        stride: int = 1,\n        padding: int = 1,\n        activation: str = \"vlin\",\n        norm: bool = True,\n        num_groups: int = 1,\n        prenorm: bool = True,\n    ):\n        super().__init__()\n        self.conv1 = CliffordG3Conv2d(\n            in_channels,\n            out_channels,\n            kernel_size=kernel_size,\n            stride=stride,\n            padding=padding,\n            bias=True,\n        )\n        self.conv2 = CliffordG3Conv2d(\n            out_channels,\n            out_channels,\n            kernel_size=kernel_size,\n            stride=stride,\n            padding=padding,\n            bias=True,\n        )\n\n        self.norm1 = CliffordG3GroupNorm(num_groups, in_channels, 3) if norm else nn.Identity()\n        self.norm2 = CliffordG3GroupNorm(num_groups, out_channels, 3) if norm else nn.Identity()\n\n        if in_channels != out_channels:\n            self.shortcut = CliffordG3Conv2d(\n                in_channels,\n                out_channels,\n                kernel_size=1,\n            )\n        else:\n            self.shortcut = nn.Identity()\n\n        self.act1 = get_activation(activation, in_channels)\n        self.act2 = get_activation(activation, out_channels)\n\n        self.prenorm = prenorm\n\n    def forward(self, x):\n        if self.prenorm:\n            out = self.conv1(self.act1(self.norm1(x)))\n            out = self.conv2(self.act2(self.norm2(out)))\n        else:\n            out = self.conv1(self.norm1(self.act1(x)))\n            out = self.conv2(self.norm2(self.act2(out)))\n\n        return out + self.shortcut(x)\n</code></pre>"},{"location":"reference/models/#cliffordlayers.models.gca.twod.CliffordG3DownBlock","title":"<code>CliffordG3DownBlock</code>","text":"<p>             Bases: <code>Module</code></p> <p>UNet encoder block for G3 Clifford convolutions on 2D grids.</p> <p>Parameters:</p> Name Type Description Default <code>in_channels</code> <code>int</code> <p>Number of input channels.</p> required <code>out_channels</code> <code>int</code> <p>Number of output channels.</p> required <code>activation</code> <code>str</code> <p>Type of activation function.</p> required <code>norm</code> <code>bool</code> <p>If True, normalization is applied. Defaults to False.</p> <code>False</code> <code>prenorm</code> <code>bool</code> <p>If True, normalization is applied before activation, otherwise after. Defaults to True.</p> <code>True</code> <code>num_groups</code> <code>int</code> <p>Number of groups for the group normalization. Defaults to 1.</p> <code>1</code> Source code in <code>cliffordlayers/models/gca/twod.py</code> <pre><code>class CliffordG3DownBlock(nn.Module):\n    \"\"\"\n    UNet encoder block for G3 Clifford convolutions on 2D grids.\n\n    Args:\n        in_channels (int): Number of input channels.\n        out_channels (int): Number of output channels.\n        activation (str): Type of activation function.\n        norm (bool, optional): If True, normalization is applied. Defaults to False.\n        prenorm (bool, optional): If True, normalization is applied before activation, otherwise after. Defaults to True.\n        num_groups (int, optional): Number of groups for the group normalization. Defaults to 1.\n    \"\"\"\n\n    def __init__(\n        self,\n        in_channels: int,\n        out_channels: int,\n        activation: str,\n        norm: bool = False,\n        prenorm: bool = True,\n        num_groups: int = 1,\n    ):\n        super().__init__()\n        self.in_channels = in_channels\n        self.out_channels = out_channels\n        self.block = CliffordG3BasicBlock2d(\n            in_channels, out_channels, activation=activation, norm=norm, prenorm=prenorm, num_groups=num_groups\n        )\n\n    def forward(self, x):\n        return self.block(x)\n</code></pre>"},{"location":"reference/models/#cliffordlayers.models.gca.twod.CliffordG3Downsample","title":"<code>CliffordG3Downsample</code>","text":"<p>             Bases: <code>Module</code></p> <p>Scale down the two-dimensional G3 Clifford feature map by a half.</p> <p>Parameters:</p> Name Type Description Default <code>n_channels</code> <code>int</code> <p>Number of channels.</p> required Source code in <code>cliffordlayers/models/gca/twod.py</code> <pre><code>class CliffordG3Downsample(nn.Module):\n    \"\"\"\n    Scale down the two-dimensional G3 Clifford feature map by a half.\n\n    Args:\n        n_channels (int): Number of channels.\n    \"\"\"\n\n    def __init__(self, n_channels):\n        super().__init__()\n        self.n_channels = n_channels\n        self.conv = CliffordG3Conv2d(\n            n_channels,\n            n_channels,\n            kernel_size=3,\n            stride=2,\n            padding=1,\n        )\n\n    def forward(self, x):\n        return self.conv(x)\n</code></pre>"},{"location":"reference/models/#cliffordlayers.models.gca.twod.CliffordG3MiddleBlock","title":"<code>CliffordG3MiddleBlock</code>","text":"<p>             Bases: <code>Module</code></p> <p>UNet middle block for G3 Clifford convolutions on 2D grids.</p> <p>Parameters:</p> Name Type Description Default <code>n_channels</code> <code>int</code> <p>Number of channels.</p> required <code>activation</code> <code>str</code> <p>Type of activation function.</p> required <code>norm</code> <code>bool</code> <p>If True, normalization is applied. Defaults to False.</p> <code>False</code> <code>prenorm</code> <code>bool</code> <p>If True, normalization is applied before activation, otherwise after. Defaults to True.</p> <code>True</code> <code>num_groups</code> <code>int</code> <p>Number of groups for the group normalization. Defaults to 1.</p> <code>1</code> Source code in <code>cliffordlayers/models/gca/twod.py</code> <pre><code>class CliffordG3MiddleBlock(nn.Module):\n    \"\"\"\n    UNet middle block for G3 Clifford convolutions on 2D grids.\n\n    Args:\n        n_channels (int): Number of channels.\n        activation (str): Type of activation function.\n        norm (bool, optional): If True, normalization is applied. Defaults to False.\n        prenorm (bool, optional): If True, normalization is applied before activation, otherwise after. Defaults to True.\n        num_groups (int, optional): Number of groups for the group normalization. Defaults to 1.\n    \"\"\"\n\n    def __init__(\n        self,\n        n_channels: int,\n        activation: str,\n        norm: bool = False,\n        prenorm: bool = True,\n        num_groups: int = 1,\n    ):\n        super().__init__()\n        self.res1 = CliffordG3BasicBlock2d(\n            n_channels,\n            n_channels,\n            activation=activation,\n            norm=norm,\n            prenorm=prenorm,\n            num_groups=num_groups,\n        )\n        self.res2 = CliffordG3BasicBlock2d(\n            n_channels,\n            n_channels,\n            activation=activation,\n            norm=norm,\n            prenorm=prenorm,\n            num_groups=num_groups,\n        )\n\n    def forward(self, x):\n        x = self.res1(x)\n        x = self.res2(x)\n        return x\n</code></pre>"},{"location":"reference/models/#cliffordlayers.models.gca.twod.CliffordG3ResNet2d","title":"<code>CliffordG3ResNet2d</code>","text":"<p>             Bases: <code>Module</code></p> <p>ResNet for G3 Clifford convolutions on 2D grids.</p> <p>Parameters:</p> Name Type Description Default <code>num_blocks</code> <code>list</code> <p>Number of blocks at each resolution.</p> required <code>in_channels</code> <code>int</code> <p>Number of input channels.</p> required <code>out_channels</code> <code>int</code> <p>Number of output channels.</p> required <code>hidden_channels</code> <code>int</code> <p>Number of hidden channels.</p> required <code>activation</code> <code>str</code> <p>Type of activation function. Defaults to \"vlin\".</p> <code>'vlin'</code> <code>block</code> <code>Module</code> <p>Type of block. Defaults to CliffordG3BasicBlock2d.</p> <code>CliffordG3BasicBlock2d</code> <code>norm</code> <code>bool</code> <p>If True, normalization is applied. Defaults to True.</p> <code>False</code> <code>num_groups</code> <code>int</code> <p>Number of groups for the group normalization. Defaults to 1.</p> <code>1</code> <code>prenorm</code> <code>bool</code> <p>If True, normalization is applied before activation, otherwise after. Defaults to True.</p> <code>True</code> Source code in <code>cliffordlayers/models/gca/twod.py</code> <pre><code>class CliffordG3ResNet2d(nn.Module):\n    \"\"\"\n    ResNet for G3 Clifford convolutions on 2D grids.\n\n    Args:\n        num_blocks (list): Number of blocks at each resolution.\n        in_channels (int): Number of input channels.\n        out_channels (int): Number of output channels.\n        hidden_channels (int): Number of hidden channels.\n        activation (str, optional): Type of activation function. Defaults to \"vlin\".\n        block (nn.Module, optional): Type of block. Defaults to CliffordG3BasicBlock2d.\n        norm (bool, optional): If True, normalization is applied. Defaults to True.\n        num_groups (int, optional): Number of groups for the group normalization. Defaults to 1.\n        prenorm (bool, optional): If True, normalization is applied before activation, otherwise after. Defaults to True.\n    \"\"\"\n\n    padding = 9\n\n    def __init__(\n        self,\n        num_blocks: list,\n        in_channels: int,\n        out_channels: int,\n        hidden_channels: int,\n        activation: str = \"vlin\",\n        block: nn.Module = CliffordG3BasicBlock2d,\n        norm: bool = False,\n        num_groups: int = 1,\n        prenorm=True,\n    ):\n        super().__init__()\n\n        # Embedding layers\n        self.conv_in1 = CliffordG3Conv2d(\n            in_channels,\n            hidden_channels,\n            kernel_size=1,\n            padding=0,\n        )\n\n        self.conv_in2 = CliffordG3Conv2d(\n            hidden_channels,\n            hidden_channels,\n        )\n\n        # Output layers\n        self.conv_out1 = CliffordG3Conv2d(\n            hidden_channels,\n            hidden_channels,\n        )\n        self.conv_out2 = CliffordG3Conv2d(\n            hidden_channels,\n            out_channels,\n            kernel_size=1,\n            padding=0,\n        )\n\n        # ResNet blocks\n        self.layers = nn.ModuleList(\n            [\n                self._make_layer(\n                    block,\n                    hidden_channels,\n                    num_blocks[i],\n                    activation=activation,\n                    norm=norm,\n                    num_groups=num_groups,\n                    prenorm=prenorm,\n                )\n                for i in range(len(num_blocks))\n            ]\n        )\n\n        self.act1 = get_activation(activation, hidden_channels)\n        self.act2 = get_activation(activation, hidden_channels)\n\n    def _make_layer(\n        self,\n        block: nn.Module,\n        channels: int,\n        num_blocks: int,\n        activation: str,\n        num_groups: int,\n        norm: bool = True,\n        prenorm: bool = True,\n    ) -&gt; nn.Sequential:\n        layers = []\n        for _ in range(num_blocks):\n            layers.append(\n                block(channels, channels, activation=activation, norm=norm, prenorm=prenorm, num_groups=num_groups)\n            )\n        return nn.Sequential(*layers)\n\n    def forward(self, x: torch.Tensor) -&gt; torch.Tensor:\n        assert x.dim() == 5\n\n        h = self.conv_in1(x)\n        h = self.act1(h)\n\n        # Second embedding layer\n        h = self.conv_in2(h)\n\n        for layer in self.layers:\n            h = layer(h)\n\n        # Output layers\n        h = self.conv_out1(h)\n        h = self.act2(h)\n        h = self.conv_out2(h)\n\n        # return output\n        return h\n</code></pre>"},{"location":"reference/models/#cliffordlayers.models.gca.twod.CliffordG3UNet2d","title":"<code>CliffordG3UNet2d</code>","text":"<p>             Bases: <code>Module</code></p> <p>U-Net architecture with Clifford G3 convolutions for 2D grids.</p> <p>Parameters:</p> Name Type Description Default <code>in_channels</code> <code>int</code> <p>Number of input channels.</p> required <code>out_channels</code> <code>int</code> <p>Number of output channels.</p> required <code>hidden_channels</code> <code>int</code> <p>Number of channels in the first hidden convolutional layer.</p> required <code>activation</code> <code>str</code> <p>Type of activation function. Defaults to \"vlin\".</p> <code>'vlin'</code> <code>norm</code> <code>bool</code> <p>If True, normalization is applied. Defaults to False.</p> <code>False</code> <code>ch_mults</code> <code>Union[Tuple[int, ...], List[int]]</code> <p>Multipliers for the number of channels at each depth.                                                 Defaults to (1, 2, 2, 2).</p> <code>(1, 2, 2, 2)</code> <code>n_blocks</code> <code>int</code> <p>Number of convolutional blocks at each resolution. Defaults to 2.</p> <code>2</code> <code>prenorm</code> <code>bool</code> <p>If True, normalization is applied before activation, otherwise after. Defaults to True.</p> <code>True</code> <code>num_groups</code> <code>int</code> <p>Number of groups for the group normalization. Defaults to 1.</p> <code>1</code> Source code in <code>cliffordlayers/models/gca/twod.py</code> <pre><code>class CliffordG3UNet2d(nn.Module):\n    \"\"\"\n    U-Net architecture with Clifford G3 convolutions for 2D grids.\n\n    Args:\n        in_channels (int): Number of input channels.\n        out_channels (int): Number of output channels.\n        hidden_channels (int): Number of channels in the first hidden convolutional layer.\n        activation (str, optional): Type of activation function. Defaults to \"vlin\".\n        norm (bool, optional): If True, normalization is applied. Defaults to False.\n        ch_mults (Union[Tuple[int, ...], List[int]], optional): Multipliers for the number of channels at each depth.\n                                                            Defaults to (1, 2, 2, 2).\n        n_blocks (int, optional): Number of convolutional blocks at each resolution. Defaults to 2.\n        prenorm (bool, optional): If True, normalization is applied before activation, otherwise after. Defaults to True.\n        num_groups (int, optional): Number of groups for the group normalization. Defaults to 1.\n    \"\"\"\n\n    def __init__(\n        self,\n        in_channels: int,\n        out_channels: int,\n        hidden_channels: int,\n        activation: str = \"vlin\",\n        norm: bool = False,\n        ch_mults: Union[Tuple[int, ...], List[int]] = (1, 2, 2, 2),\n        n_blocks: int = 2,\n        prenorm: bool = True,\n        num_groups: int = 1,\n    ) -&gt; None:\n        super().__init__()\n\n        self.out_channels = out_channels\n\n        # Number of resolutions\n        n_resolutions = len(ch_mults)\n\n        self.conv1 = CliffordG3Conv2d(\n            in_channels,\n            hidden_channels,\n            kernel_size=3,\n            padding=1,\n        )\n\n        # Decreasing resolution\n        down = []\n        # Number of channels\n        out_channels = in_channels = hidden_channels\n        # For each resolution\n        for i in range(n_resolutions):\n            # Number of output channels at this resolution\n            out_channels = in_channels * ch_mults[i]\n            for _ in range(n_blocks):\n                down.append(\n                    CliffordG3DownBlock(\n                        in_channels,\n                        out_channels,\n                        activation=activation,\n                        norm=norm,\n                        prenorm=prenorm,\n                        num_groups=num_groups,\n                    )\n                )\n                in_channels = out_channels\n            # Down sample at all resolutions except the last\n            if i &lt; n_resolutions - 1:\n                down.append(\n                    CliffordG3Downsample(\n                        in_channels,\n                    )\n                )\n\n        # Combine the set of modules\n        self.down = nn.ModuleList(down)\n\n        # Middle block\n        self.middle = CliffordG3MiddleBlock(out_channels, activation=activation, norm=norm, prenorm=prenorm)\n\n        # Increasing resolution\n        up = []\n        # Number of channels\n        in_channels = out_channels\n        # For each resolution\n        for i in reversed(range(n_resolutions)):\n            # `n_blocks` at the same resolution\n            out_channels = in_channels\n            for _ in range(n_blocks):\n                up.append(\n                    CliffordG3UpBlock(\n                        in_channels,\n                        out_channels,\n                        activation=activation,\n                        norm=norm,\n                        prenorm=prenorm,\n                        num_groups=num_groups,\n                    )\n                )\n            # Final block to reduce the number of channels\n            out_channels = in_channels // ch_mults[i]\n            up.append(\n                CliffordG3UpBlock(\n                    in_channels,\n                    out_channels,\n                    activation=activation,\n                    norm=norm,\n                    prenorm=prenorm,\n                )\n            )\n            in_channels = out_channels\n            # Up sample at all resolutions except last\n            if i &gt; 0:\n                up.append(\n                    CliffordUpsample(\n                        in_channels,\n                    )\n                )\n\n        # Combine the set of modules\n        self.up = nn.ModuleList(up)\n\n        self.activation = get_activation(activation, out_channels)\n\n        if norm:\n            self.norm = CliffordG3GroupNorm(num_groups, out_channels, 3)\n        else:\n            self.norm = nn.Identity()\n\n        # Output layers\n        self.conv2 = CliffordG3Conv2d(\n            in_channels,\n            self.out_channels,\n            kernel_size=3,\n            padding=1,\n        )\n\n    def forward(self, x: torch.Tensor):\n        assert x.dim() == 5\n\n        x = self.conv1(x)\n\n        h = [x]\n        for m in self.down:\n            x = m(x)\n            h.append(x)\n\n        x = self.middle(x)\n\n        for m in self.up:\n            if isinstance(m, CliffordUpsample):\n                x = m(x)\n            else:\n                # Get the skip connection from first half of U-Net and concatenate\n                s = h.pop()\n                x = torch.cat((x, s), dim=1)\n                x = m(x)\n\n        x = self.activation(self.norm(x))\n        x = self.conv2(x)\n        return x\n</code></pre>"},{"location":"reference/models/#cliffordlayers.models.gca.twod.CliffordG3UpBlock","title":"<code>CliffordG3UpBlock</code>","text":"<p>             Bases: <code>Module</code></p> <p>UNet decoder block for G3 Clifford convolutions on 2D grids.</p> <p>Parameters:</p> Name Type Description Default <code>in_channels</code> <code>int</code> <p>Number of input channels.</p> required <code>out_channels</code> <code>int</code> <p>Number of output channels.</p> required <code>activation</code> <code>str</code> <p>Type of activation function.</p> required <code>norm</code> <code>bool</code> <p>If True, normalization is applied. Defaults to False.</p> <code>False</code> <code>prenorm</code> <code>bool</code> <p>If True, normalization is applied before activation, otherwise after. Defaults to True.</p> <code>True</code> <code>num_groups</code> <code>int</code> <p>Number of groups for the group normalization. Defaults to 1.</p> <code>1</code> Source code in <code>cliffordlayers/models/gca/twod.py</code> <pre><code>class CliffordG3UpBlock(nn.Module):\n    \"\"\"\n    UNet decoder block for G3 Clifford convolutions on 2D grids.\n\n    Args:\n        in_channels (int): Number of input channels.\n        out_channels (int): Number of output channels.\n        activation (str): Type of activation function.\n        norm (bool, optional): If True, normalization is applied. Defaults to False.\n        prenorm (bool, optional): If True, normalization is applied before activation, otherwise after. Defaults to True.\n        num_groups (int, optional): Number of groups for the group normalization. Defaults to 1.\n    \"\"\"\n\n    def __init__(\n        self,\n        in_channels: int,\n        out_channels: int,\n        activation: str,\n        norm: bool = False,\n        prenorm: bool = True,\n        num_groups: int = 1,\n    ):\n        super().__init__()\n        # The input has `in_channels + out_channels` because we concatenate the output of the same resolution\n        # from the first half of the U-Net\n        self.res = CliffordG3BasicBlock2d(\n            in_channels + out_channels,\n            out_channels,\n            activation=activation,\n            norm=norm,\n            prenorm=prenorm,\n            num_groups=num_groups,\n        )\n\n    def forward(self, x):\n        return self.res(x)\n</code></pre>"},{"location":"reference/models/#cliffordlayers.models.gca.twod.CliffordUpsample","title":"<code>CliffordUpsample</code>","text":"<p>             Bases: <code>Module</code></p> <p>Scale up the two-dimensional G3 Clifford feature map by a factor of two.</p> <p>Parameters:</p> Name Type Description Default <code>n_channels</code> <code>int</code> <p>Number of channels.</p> required Source code in <code>cliffordlayers/models/gca/twod.py</code> <pre><code>class CliffordUpsample(nn.Module):\n    \"\"\"\n    Scale up the two-dimensional G3 Clifford feature map by a factor of two.\n\n    Args:\n        n_channels (int): Number of channels.\n    \"\"\"\n\n    def __init__(self, n_channels: int):\n        super().__init__()\n        self.conv = CliffordG3ConvTranspose2d(\n            n_channels,\n            n_channels,\n            4,\n            2,\n            1,\n        )\n\n    def forward(self, x):\n        return self.conv(x)\n</code></pre>"},{"location":"reference/models/#3d-models","title":"3D models","text":"<p>The following code snippet initializes a 3D Clifford FNO.</p> <pre><code>import torch.nn.functional as F\n\nfrom cliffordlayers.models.models_3d import (\n    CliffordMaxwellNet3d,\n    CliffordFourierBasicBlock3d,\n)\nmodel = CliffordMaxwellNet3d(\n        g = [1, 1, 1],\n        block = CliffordFourierBasicBlock3d,\n        num_blocks = [1, 1, 1, 1],\n        in_channels = 4,\n        out_channels = 1,\n        hidden_channels = 16,\n        activation = F.gelu,\n        norm = False,\n    )\n</code></pre>"},{"location":"reference/models/#cliffordlayers.models.basic.threed.CliffordFourierBasicBlock3d","title":"<code>CliffordFourierBasicBlock3d</code>","text":"<p>             Bases: <code>Module</code></p> <p>3D building block for Clifford FNO architectures.</p> <p>Parameters:</p> Name Type Description Default <code>g</code> <code>Union[tuple, list, Tensor]</code> <p>Signature of Clifford algebra.</p> required <code>in_channels</code> <code>int</code> <p>Number of input channels.</p> required <code>out_channels</code> <code>int</code> <p>Number of output channels.</p> required <code>activation</code> <code>Callable</code> <p>Activation function. Defaults to F.gelu.</p> <code>gelu</code> <code>kernel_size</code> <code>int</code> <p>Kernel size of Clifford convolution. Defaults to 3.</p> <code>1</code> <code>stride</code> <code>int</code> <p>Stride of Clifford convolution. Defaults to 1.</p> <code>1</code> <code>padding</code> <code>int</code> <p>Padding of Clifford convolution. Defaults to 1.</p> <code>0</code> <code>norm</code> <code>bool</code> <p>Wether to use Clifford (group) normalization. Defaults to False.</p> <code>False</code> <code>num_groups</code> <code>int</code> <p>Number of groups when using Clifford (group) normalization. Defaults to 1.</p> <code>1</code> <code>modes1</code> <code>int</code> <p>Number of Fourier modes in the first dimension. Defaults to 8.</p> <code>8</code> <code>modes2</code> <code>int</code> <p>Number of Fourier modes in the second dimension. Defaults to 8.</p> <code>8</code> <code>modes3</code> <code>int</code> <p>Number of Fourier modes in the third dimension. Defaults to 8.</p> <code>8</code> Source code in <code>cliffordlayers/models/basic/threed.py</code> <pre><code>class CliffordFourierBasicBlock3d(nn.Module):\n    \"\"\"3D building block for Clifford FNO architectures.\n\n    Args:\n        g (Union[tuple, list, torch.Tensor]): Signature of Clifford algebra.\n        in_channels (int): Number of input channels.\n        out_channels (int): Number of output channels.\n        activation (Callable, optional): Activation function. Defaults to F.gelu.\n        kernel_size (int, optional): Kernel size of Clifford convolution. Defaults to 3.\n        stride (int, optional): Stride of Clifford convolution. Defaults to 1.\n        padding (int, optional): Padding of Clifford convolution. Defaults to 1.\n        norm (bool, optional): Wether to use Clifford (group) normalization. Defaults to False.\n        num_groups (int, optional): Number of groups when using Clifford (group) normalization. Defaults to 1.\n        modes1 (int, optional): Number of Fourier modes in the first dimension. Defaults to 8.\n        modes2 (int, optional): Number of Fourier modes in the second dimension. Defaults to 8.\n        modes3 (int, optional): Number of Fourier modes in the third dimension. Defaults to 8.\n    \"\"\"\n\n    expansion: int = 1\n\n    def __init__(\n        self,\n        g: Union[tuple, list, torch.Tensor],\n        in_channels: int,\n        out_channels: int,\n        activation: Callable = F.gelu,\n        kernel_size: int = 1,\n        stride: int = 1,\n        padding: int = 0,\n        norm: bool = False,\n        num_groups: int = 1,\n        modes1: int = 8,\n        modes2: int = 8,\n        modes3: int = 8,\n    ):\n        super().__init__()\n        self.fourier = CliffordSpectralConv3d(\n            g,\n            in_channels,\n            out_channels,\n            modes1=modes1,\n            modes2=modes2,\n            modes3=modes3,\n        )\n        self.conv = CliffordConv3d(\n            g,\n            in_channels,\n            out_channels,\n            kernel_size=kernel_size,\n            stride=stride,\n            padding=padding,\n            bias=True,\n        )\n        self.norm = CliffordGroupNorm3d(g, num_groups, in_channels) if norm else nn.Identity()\n        self.activation = activation\n\n    def forward(self, x: torch.Tensor) -&gt; torch.Tensor:\n        x1 = self.fourier(x)\n        x2 = self.conv(x)\n        return self.activation(self.norm(x1 + x2))\n</code></pre>"},{"location":"reference/models/#cliffordlayers.models.basic.threed.CliffordMaxwellNet3d","title":"<code>CliffordMaxwellNet3d</code>","text":"<p>             Bases: <code>Module</code></p> <p>3D building block for Clifford architectures with ResNet backbone network. The backbone networks follows these three steps:     1. Clifford vector+bivector encoding.     2. Basic blocks as provided.     3. Clifford vector+bivector decoding.</p> <p>Parameters:</p> Name Type Description Default <code>g</code> <code>Union[tuple, list, Tensor]</code> <p>Signature of Clifford algebra.</p> required <code>block</code> <code>Module</code> <p>Choice of basic blocks.</p> required <code>num_blocks</code> <code>list</code> <p>List of basic blocks in each residual block.</p> required <code>in_channels</code> <code>int</code> <p>Number of input channels.</p> required <code>out_channels</code> <code>int</code> <p>Number of output channels.</p> required <code>activation</code> <code>Callable</code> <p>Activation function. Defaults to F.gelu.</p> required <code>norm</code> <code>bool</code> <p>Wether to use Clifford (group) normalization. Defaults to False.</p> <code>False</code> <code>num_groups</code> <code>int</code> <p>Number of groups when using Clifford (group) normalization. Defaults to 1.</p> <code>1</code> Source code in <code>cliffordlayers/models/basic/threed.py</code> <pre><code>class CliffordMaxwellNet3d(nn.Module):\n    \"\"\"3D building block for Clifford architectures with ResNet backbone network.\n    The backbone networks follows these three steps:\n        1. Clifford vector+bivector encoding.\n        2. Basic blocks as provided.\n        3. Clifford vector+bivector decoding.\n\n    Args:\n        g (Union[tuple, list, torch.Tensor]): Signature of Clifford algebra.\n        block (nn.Module): Choice of basic blocks.\n        num_blocks (list): List of basic blocks in each residual block.\n        in_channels (int): Number of input channels.\n        out_channels (int): Number of output channels.\n        activation (Callable, optional): Activation function. Defaults to F.gelu.\n        norm (bool, optional): Wether to use Clifford (group) normalization. Defaults to False.\n        num_groups (int, optional): Number of groups when using Clifford (group) normalization. Defaults to 1.\n    \"\"\"\n\n    # For periodic boundary conditions, set padding = 0.\n    padding = 2\n\n    def __init__(\n        self,\n        g: Union[tuple, list, torch.Tensor],\n        block: nn.Module,\n        num_blocks: list,\n        in_channels: int,\n        out_channels: int,\n        hidden_channels: int,\n        activation: Callable,\n        norm: bool = False,\n        num_groups: int = 1,\n    ):\n        super().__init__()\n\n        self.activation = activation\n        # Encoding and decoding layers.\n        self.encoder = CliffordConv3dMaxwellEncoder(\n            g,\n            in_channels=in_channels,\n            out_channels=hidden_channels,\n            kernel_size=1,\n            padding=0,\n        )\n        self.decoder = CliffordConv3dMaxwellDecoder(\n            g,\n            in_channels=hidden_channels,\n            out_channels=out_channels,\n            kernel_size=1,\n            padding=0,\n        )\n\n        # Residual blocks.\n        self.layers = nn.ModuleList(\n            [\n                self._make_basic_block(\n                    g,\n                    block,\n                    hidden_channels,\n                    num_blocks[i],\n                    activation=activation,\n                    norm=norm,\n                    num_groups=num_groups,\n                )\n                for i in range(len(num_blocks))\n            ]\n        )\n\n    def _make_basic_block(\n        self,\n        g,\n        block: nn.Module,\n        hidden_channels: int,\n        num_blocks: int,\n        activation: Callable,\n        norm: bool,\n        num_groups: int,\n    ) -&gt; nn.Sequential:\n        blocks = []\n        for _ in range(num_blocks):\n            blocks.append(\n                block(\n                    g,\n                    hidden_channels,\n                    hidden_channels,\n                    activation=activation,\n                    norm=norm,\n                    num_groups=num_groups,\n                )\n            )\n        return nn.Sequential(*blocks)\n\n    def forward(self, x: torch.Tensor) -&gt; torch.Tensor:\n        assert x.dim() == 6\n\n        # Encoding layer.\n        x = self.encoder(self.activation(x))\n\n        # Embed for non-periodic boundaries.\n        if self.padding &gt; 0:\n            B_dim, C_dim, *D_dims, I_dim = range(len(x.shape))\n            x = x.permute(B_dim, I_dim, C_dim, *D_dims)\n            x = F.pad(x, [0, self.padding, 0, self.padding, 0, self.padding])\n            B_dim, I_dim, C_dim, *D_dims = range(len(x.shape))\n            x = x.permute(B_dim, C_dim, *D_dims, I_dim)\n\n        # Apply residual layers.\n        for layer in self.layers:\n            x = layer(x)\n\n        # Decoding layer.\n        if self.padding &gt; 0:\n            B_dim, C_dim, *D_dims, I_dim = range(len(x.shape))\n            x = x.permute(B_dim, I_dim, C_dim, *D_dims)\n            x = x[..., : -self.padding, : -self.padding, : -self.padding]\n            B_dim, I_dim, C_dim, *D_dims = range(len(x.shape))\n            x = x.permute(B_dim, C_dim, *D_dims, I_dim)\n\n        # Output layer.\n        x = self.decoder(x)\n        return x\n</code></pre>"},{"location":"reference/modules/","title":"Modules","text":"<p>We provide linear Clifford layers; 1D, 2D, 3D Clifford convolution layers, and 2D, 3D Clifford Fourier transform layers. Additionally, Clifford normalization schemes are provided.</p> <p>All these modules are available for different algebras.</p>"},{"location":"reference/modules/#cliffordlayers.nn.modules.cliffordlinear.CliffordLinear","title":"<code>CliffordLinear</code>","text":"<p>             Bases: <code>Module</code></p> <p>Clifford linear layer.</p> <p>Parameters:</p> Name Type Description Default <code>g</code> <code>Union[List, Tuple]</code> <p>Clifford signature tensor.</p> required <code>in_channels</code> <code>int</code> <p>Number of input channels.</p> required <code>out_channels</code> <code>int</code> <p>Number of output channels.</p> required <code>bias</code> <code>bool</code> <p>If True, adds a learnable bias to the output. Defaults to True.</p> <code>True</code> Source code in <code>cliffordlayers/nn/modules/cliffordlinear.py</code> <pre><code>class CliffordLinear(nn.Module):\n    \"\"\"Clifford linear layer.\n\n    Args:\n        g (Union[List, Tuple]): Clifford signature tensor.\n        in_channels (int): Number of input channels.\n        out_channels (int): Number of output channels.\n        bias (bool, optional): If True, adds a learnable bias to the output. Defaults to True.\n\n    \"\"\"\n\n    def __init__(\n        self,\n        g,\n        in_channels: int,\n        out_channels: int,\n        bias: bool = True,\n    ) -&gt; None:\n        super().__init__()\n        sig = CliffordSignature(g)\n\n        self.register_buffer(\"g\", sig.g)\n        self.dim = sig.dim\n        self.n_blades = sig.n_blades\n\n        if self.dim == 1:\n            self._get_kernel = get_1d_clifford_kernel\n        elif self.dim == 2:\n            self._get_kernel = get_2d_clifford_kernel\n        elif self.dim == 3:\n            self._get_kernel = get_3d_clifford_kernel\n        else:\n            raise NotImplementedError(\n                f\"Clifford linear layers are not implemented for {self.dim} dimensions. Wrong Clifford signature.\"\n            )\n\n        self.in_channels = in_channels\n        self.out_channels = out_channels\n        self.weight = nn.Parameter(torch.empty(self.n_blades, out_channels, in_channels))\n\n        if bias:\n            self.bias = nn.Parameter(torch.empty(self.n_blades, out_channels))\n        else:\n            self.register_parameter(\"bias\", None)\n\n        self.reset_parameters()\n\n    def reset_parameters(self):\n        # Initialization of the Clifford linear weight and bias tensors.\n        # The number of blades is taken into account when calculated the bounds of Kaiming uniform.\n        nn.init.kaiming_uniform_(\n            self.weight.view(self.out_channels, self.in_channels * self.n_blades),\n            a=math.sqrt(5),\n        )\n        if self.bias is not None:\n            fan_in, _ = nn.init._calculate_fan_in_and_fan_out(\n                self.weight.view(self.out_channels, self.in_channels * self.n_blades)\n            )\n            bound = 1 / math.sqrt(fan_in)\n            nn.init.uniform_(self.bias, -bound, bound)\n\n    def forward(self, x: torch.Tensor) -&gt; torch.Tensor:\n        # Reshape x such that the Clifford kernel can be applied.\n        B, _, I = x.shape\n        if not (I == self.n_blades):\n            raise ValueError(f\"Input has {I} blades, but Clifford layer expects {self.n_blades}.\")\n        B_dim, C_dim, I_dim = range(len(x.shape))\n        x = x.permute(B_dim, -1, C_dim)\n        x = x.reshape(B, -1)\n        # Get Clifford kernel, apply it.\n        _, weight = self._get_kernel(self.weight, self.g)\n        output = F.linear(x, weight, self.bias.view(-1))\n        # Reshape back.\n        output = output.view(B, I, -1)\n        B_dim, I_dim, C_dim = range(len(output.shape))\n        output = output.permute(B_dim, C_dim, I_dim)\n        return output\n</code></pre>"},{"location":"reference/modules/#cliffordlayers.nn.modules.cliffordconv.CliffordConv1d","title":"<code>CliffordConv1d</code>","text":"<p>             Bases: <code>_CliffordConvNd</code></p> <p>1d Clifford convolution.</p> <p>Parameters:</p> Name Type Description Default <code>g</code> <code>Union[tuple, list, Tensor]</code> <p>Clifford signature.</p> required <code>in_channels</code> <code>int</code> <p>Number of channels in the input tensor.</p> required <code>out_channels</code> <code>int</code> <p>Number of channels produced by the convolution.</p> required <code>kernel_size</code> <code>int</code> <p>Size of the convolving kernel.</p> <code>3</code> <code>stride</code> <code>int</code> <p>Stride of the convolution.</p> <code>1</code> <code>padding</code> <code>int</code> <p>padding added to both sides of the input.</p> <code>0</code> <code>dilation</code> <code>int</code> <p>Spacing between kernel elements.</p> <code>1</code> <code>groups</code> <code>int</code> <p>Number of blocked connections from input channels to output channels.</p> <code>1</code> <code>bias</code> <code>bool</code> <p>If True, adds a learnable bias to the output.</p> <code>True</code> <code>padding_mode</code> <code>str</code> <p>Padding to use.</p> <code>'zeros'</code> Source code in <code>cliffordlayers/nn/modules/cliffordconv.py</code> <pre><code>class CliffordConv1d(_CliffordConvNd):\n    \"\"\"1d Clifford convolution.\n\n    Args:\n        g (Union[tuple, list, torch.Tensor]): Clifford signature.\n        in_channels (int): Number of channels in the input tensor.\n        out_channels (int): Number of channels produced by the convolution.\n        kernel_size (int): Size of the convolving kernel.\n        stride (int): Stride of the convolution.\n        padding (int): padding added to both sides of the input.\n        dilation (int): Spacing between kernel elements.\n        groups (int): Number of blocked connections from input channels to output channels.\n        bias (bool): If True, adds a learnable bias to the output.\n        padding_mode (str): Padding to use.\n    \"\"\"\n\n    def __init__(\n        self,\n        g: Union[tuple, list, torch.Tensor],\n        in_channels: int,\n        out_channels: int,\n        kernel_size: int = 3,\n        stride: int = 1,\n        padding: int = 0,\n        dilation: int = 1,\n        groups: int = 1,\n        bias: bool = True,\n        padding_mode: str = \"zeros\",\n    ) -&gt; None:\n        kernel_size_ = _single(kernel_size)\n        stride_ = _single(stride)\n        padding_ = _single(padding)\n        dilation_ = _single(dilation)\n\n        super().__init__(\n            g,\n            in_channels,\n            out_channels,\n            kernel_size_,\n            stride_,\n            padding_,\n            dilation_,\n            groups,\n            bias,\n            padding_mode,\n        )\n        if not self.dim == 1:\n            raise NotImplementedError(\"Wrong Clifford signature for CliffordConv1d.\")\n\n    def forward(self, x: torch.Tensor) -&gt; torch.Tensor:\n        *_, I = x.shape\n        if not (I == self.n_blades):\n            raise ValueError(f\"Input has {I} blades, but Clifford layer expects {self.n_blades}.\")\n        return super().forward(x, F.conv1d)\n</code></pre>"},{"location":"reference/modules/#cliffordlayers.nn.modules.cliffordconv.CliffordConv2d","title":"<code>CliffordConv2d</code>","text":"<p>             Bases: <code>_CliffordConvNd</code></p> <p>2d Clifford convolution.</p> <p>Parameters:</p> Name Type Description Default <code>g</code> <code>Union[tuple, list, Tensor]</code> <p>Clifford signature.</p> required <code>in_channels</code> <code>int</code> <p>Number of channels in the input tensor.</p> required <code>out_channels</code> <code>int</code> <p>Number of channels produced by the convolution.</p> required <code>kernel_size</code> <code>Union[int, Tuple[int, int]]</code> <p>Size of the convolving kernel.</p> <code>3</code> <code>stride</code> <code>Union[int, Tuple[int, int]]</code> <p>Stride of the convolution.</p> <code>1</code> <code>padding</code> <code>Union[int, Tuple[int, int]]</code> <p>padding added to both sides of the input.</p> <code>0</code> <code>dilation</code> <code>Union[int, Tuple[int, int]]</code> <p>Spacing between kernel elements.</p> <code>1</code> <code>groups</code> <code>int</code> <p>Number of blocked connections from input channels to output channels.</p> <code>1</code> <code>bias</code> <code>bool</code> <p>If True, adds a learnable bias to the output.</p> <code>True</code> <code>padding_mode</code> <code>str</code> <p>Padding to use.</p> <code>'zeros'</code> <code>rotation</code> <code>bool</code> <p>If True, enables the rotation kernel for Clifford convolution.</p> <code>False</code> Source code in <code>cliffordlayers/nn/modules/cliffordconv.py</code> <pre><code>class CliffordConv2d(_CliffordConvNd):\n    \"\"\"2d Clifford convolution.\n\n    Args:\n        g (Union[tuple, list, torch.Tensor]): Clifford signature.\n        in_channels (int): Number of channels in the input tensor.\n        out_channels (int): Number of channels produced by the convolution.\n        kernel_size (Union[int, Tuple[int, int]]): Size of the convolving kernel.\n        stride (Union[int, Tuple[int, int]]): Stride of the convolution.\n        padding (Union[int, Tuple[int, int]]): padding added to both sides of the input.\n        dilation (Union[int, Tuple[int, int]]): Spacing between kernel elements.\n        groups (int): Number of blocked connections from input channels to output channels.\n        bias (bool): If True, adds a learnable bias to the output.\n        padding_mode (str): Padding to use.\n        rotation (bool): If True, enables the rotation kernel for Clifford convolution.\n    \"\"\"\n\n    def __init__(\n        self,\n        g: Union[tuple, list, torch.Tensor],\n        in_channels: int,\n        out_channels: int,\n        kernel_size: int = 3,\n        stride: int = 1,\n        padding: int = 0,\n        dilation: int = 1,\n        groups: int = 1,\n        bias: bool = True,\n        padding_mode: str = \"zeros\",\n        rotation: bool = False,\n    ):\n        kernel_size_ = _pair(kernel_size)\n        stride_ = _pair(stride)\n        padding_ = padding if isinstance(padding, str) else _pair(padding)\n        dilation_ = _pair(dilation)\n\n        super().__init__(\n            g,\n            in_channels,\n            out_channels,\n            kernel_size_,\n            stride_,\n            padding_,\n            dilation_,\n            groups,\n            bias,\n            padding_mode,\n            rotation,\n        )\n        if not self.dim == 2:\n            raise NotImplementedError(\"Wrong Clifford signature for CliffordConv2d.\")\n\n    def forward(self, x: torch.Tensor) -&gt; torch.Tensor:\n        *_, I = x.shape\n        if not (I == self.n_blades):\n            raise ValueError(f\"Input has {I} blades, but Clifford layer expects {self.n_blades}.\")\n        return super().forward(x, F.conv2d)\n</code></pre>"},{"location":"reference/modules/#cliffordlayers.nn.modules.cliffordconv.CliffordConv3d","title":"<code>CliffordConv3d</code>","text":"<p>             Bases: <code>_CliffordConvNd</code></p> <p>3d Clifford convolution.</p> <p>Parameters:</p> Name Type Description Default <code>g</code> <code>Union[tuple, list, Tensor]</code> <p>Clifford signature.</p> required <code>in_channels</code> <code>int</code> <p>Number of channels in the input tensor.</p> required <code>out_channels</code> <code>int</code> <p>Number of channels produced by the convolution.</p> required <code>kernel_size</code> <code>Union[int, Tuple[int, int, int]]</code> <p>Size of the convolving kernel.</p> <code>3</code> <code>stride</code> <code>Union[int, Tuple[int, int, int]]</code> <p>Stride of the convolution.</p> <code>1</code> <code>padding</code> <code>Union[int, Tuple[int, int, int]]</code> <p>padding added to all sides of the input.</p> <code>0</code> <code>dilation</code> <code>Union[int, Tuple[int, int, int]]</code> <p>Spacing between kernel elements.</p> <code>1</code> <code>groups</code> <code>int</code> <p>Number of blocked connections from input channels to output channels.</p> <code>1</code> <code>bias</code> <code>bool</code> <p>If True, adds a learnable bias to the output.</p> <code>True</code> <code>padding_mode</code> <code>str</code> <p>Padding to use.</p> <code>'zeros'</code> Source code in <code>cliffordlayers/nn/modules/cliffordconv.py</code> <pre><code>class CliffordConv3d(_CliffordConvNd):\n    \"\"\"3d Clifford convolution.\n\n    Args:\n        g (Union[tuple, list, torch.Tensor]): Clifford signature.\n        in_channels (int): Number of channels in the input tensor.\n        out_channels (int): Number of channels produced by the convolution.\n        kernel_size (Union[int, Tuple[int, int, int]]): Size of the convolving kernel.\n        stride (Union[int, Tuple[int, int, int]]): Stride of the convolution.\n        padding (Union[int, Tuple[int, int, int]]): padding added to all sides of the input.\n        dilation (Union[int, Tuple[int, int, int]]): Spacing between kernel elements.\n        groups (int): Number of blocked connections from input channels to output channels.\n        bias (bool): If True, adds a learnable bias to the output.\n        padding_mode (str): Padding to use.\n    \"\"\"\n\n    def __init__(\n        self,\n        g: Union[tuple, list, torch.Tensor],\n        in_channels: int,\n        out_channels: int,\n        kernel_size: int = 3,\n        stride: int = 1,\n        padding: int = 0,\n        dilation: int = 1,\n        groups: int = 1,\n        bias: bool = True,\n        padding_mode: str = \"zeros\",\n    ):\n        kernel_size_ = _triple(kernel_size)\n        stride_ = _triple(stride)\n        padding_ = padding if isinstance(padding, str) else _triple(padding)\n        dilation_ = _triple(dilation)\n\n        super().__init__(\n            g,\n            in_channels,\n            out_channels,\n            kernel_size_,\n            stride_,\n            padding_,\n            dilation_,\n            groups,\n            bias,\n            padding_mode,\n        )\n        if not self.dim == 3:\n            raise NotImplementedError(\"Wrong Clifford signature for CliffordConv3d.\")\n\n    def forward(self, x: torch.Tensor) -&gt; torch.Tensor:\n        *_, I = x.shape\n        if not (I == self.n_blades):\n            raise ValueError(f\"Input has {I} blades, but Clifford layer expects {self.n_blades}.\")\n        return super().forward(x, F.conv3d)\n</code></pre>"},{"location":"reference/modules/#cliffordlayers.nn.modules.cliffordfourier.CliffordSpectralConv2d","title":"<code>CliffordSpectralConv2d</code>","text":"<p>             Bases: <code>Module</code></p> <p>2d Clifford Fourier layer. Performs following three steps:     1. Clifford Fourier transform over the multivector of 2d Clifford algebras, based on complex Fourier transforms using pytorch.fft.fft2.     2. Weight multiplication in the Clifford Fourier space using the geometric product.     3. Inverse Clifford Fourier transform, based on inverse complex Fourier transforms using pytorch.fft.ifft2.</p> <p>Parameters:</p> Name Type Description Default <code>g</code> <code>Union[tuple, list, Tensor]</code> <p>Signature of Clifford algebra.</p> required <code>in_channels</code> <code>int</code> <p>Number of input channels.</p> required <code>out_channels</code> <code>int</code> <p>Number of output channels.</p> required <code>modes1</code> <code>int</code> <p>Number of non-zero Fourier modes in the first dimension.</p> required <code>modes2</code> <code>int</code> <p>Number of non-zero Fourier modes in the second dimension.</p> required <code>multiply</code> <code>bool</code> <p>Multipliation in the Fourier space. If set to False this class only crops high-frequency modes.</p> <code>True</code> Source code in <code>cliffordlayers/nn/modules/cliffordfourier.py</code> <pre><code>class CliffordSpectralConv2d(nn.Module):\n    \"\"\"2d Clifford Fourier layer.\n    Performs following three steps:\n        1. Clifford Fourier transform over the multivector of 2d Clifford algebras, based on complex Fourier transforms using [pytorch.fft.fft2](https://pytorch.org/docs/stable/generated/torch.fft.fft2.html#torch.fft.fft2).\n        2. Weight multiplication in the Clifford Fourier space using the geometric product.\n        3. Inverse Clifford Fourier transform, based on inverse complex Fourier transforms using [pytorch.fft.ifft2](https://pytorch.org/docs/stable/generated/torch.fft.ifft2.html#torch.fft.ifft2).\n\n    Args:\n        g ((Union[tuple, list, torch.Tensor]): Signature of Clifford algebra.\n        in_channels (int): Number of input channels.\n        out_channels (int): Number of output channels.\n        modes1 (int): Number of non-zero Fourier modes in the first dimension.\n        modes2 (int): Number of non-zero Fourier modes in the second dimension.\n        multiply (bool): Multipliation in the Fourier space. If set to False this class only crops high-frequency modes.\n\n    \"\"\"\n\n    def __init__(\n        self,\n        g: Union[tuple, list, torch.Tensor],\n        in_channels: int,\n        out_channels: int,\n        modes1: int,\n        modes2: int,\n        multiply: bool = True,\n    ) -&gt; None:\n        super().__init__()\n        sig = CliffordSignature(g)\n        # To allow move to same device as module.\n        self.register_buffer(\"g\", sig.g)\n        self.dim = sig.dim\n        if self.dim != 2:\n            raise ValueError(\"g must be a 2D Clifford algebra\")\n\n        self.n_blades = sig.n_blades\n        self.in_channels = in_channels\n        self.out_channels = out_channels\n        self.modes1 = modes1\n        self.modes2 = modes2\n        self.multiply = multiply\n\n        # Initialize weight parameters.\n        if multiply:\n            scale = 1 / (in_channels * out_channels)\n            self.weights = nn.Parameter(\n                scale * torch.rand(4, out_channels, in_channels, self.modes1 * 2, self.modes2 * 2, dtype=torch.float32)\n            )\n\n    def forward(self, x: torch.Tensor) -&gt; torch.Tensor:\n        # Reshape x such that FFT can be applied to dual pairs.\n        B, _, *D, I = x.shape\n        *_, I = x.shape\n        if not (I == self.n_blades):\n            raise ValueError(f\"Input has {I} blades, but Clifford layer expects {self.n_blades}.\")\n\n        dual_1 = torch.view_as_complex(torch.stack((x[..., 0], x[..., 3]), dim=-1))\n        dual_2 = torch.view_as_complex(torch.stack((x[..., 1], x[..., 2]), dim=-1))\n        dual_1_ft = torch.fft.fft2(dual_1)\n        dual_2_ft = torch.fft.fft2(dual_2)\n\n        # Add dual pairs again to multivector in the Fourier space.\n        multivector_ft = torch.cat(\n            (\n                dual_1_ft.real,\n                dual_2_ft.real,\n                dual_2_ft.imag,\n                dual_1_ft.imag,\n            ),\n            dim=1,\n        )\n\n        # Reserve Cifford output Fourier modes.\n        out_ft = torch.zeros(\n            B,\n            self.out_channels * self.n_blades,\n            *D,\n            dtype=torch.float,\n            device=multivector_ft.device,\n        )\n\n        # Concatenate positive and negative modes, such that the geometric product can be applied in one go.\n        input_mul = torch.cat(\n            (\n                torch.cat(\n                    (\n                        multivector_ft[:, :, : self.modes1, : self.modes2],\n                        multivector_ft[:, :, : self.modes1, -self.modes2 :],\n                    ),\n                    -1,\n                ),\n                torch.cat(\n                    (\n                        multivector_ft[:, :, -self.modes1 :, : self.modes2],\n                        multivector_ft[:, :, -self.modes1 :, -self.modes2 :],\n                    ),\n                    -1,\n                ),\n            ),\n            -2,\n        )\n\n        # Get Clifford weight tensor and apply the geometric product in the Fourier space.\n        if self.multiply:\n            _, kernel = get_2d_clifford_kernel(self.weights, self.g)\n            output_mul = batchmul2d(input_mul, kernel)\n        else:\n            output_mul = input_mul\n\n        # Fill the output modes, i.e. cut away high-frequency modes.\n        out_ft[:, :, : self.modes1, : self.modes2] = output_mul[:, :, : self.modes1, : self.modes2]\n        out_ft[:, :, -self.modes1 :, : self.modes2] = output_mul[:, :, -self.modes1 :, : self.modes2]\n        out_ft[:, :, : self.modes1, -self.modes2 :] = output_mul[:, :, : self.modes1, -self.modes2 :]\n        out_ft[:, :, -self.modes1 :, -self.modes2 :] = output_mul[:, :, -self.modes1 :, -self.modes2 :]\n\n        # Reshape output such that inverse FFTs can be applied to the dual pairs.\n        out_ft = out_ft.reshape(B, I, -1, *out_ft.shape[-2:])\n        B_dim, I_dim, C_dim, *D_dims = range(len(out_ft.shape))\n        out_ft = out_ft.permute(B_dim, C_dim, *D_dims, I_dim)\n        out_dual_1 = torch.view_as_complex(torch.stack((out_ft[..., 0], out_ft[..., 3]), dim=-1))\n        out_dual_2 = torch.view_as_complex(torch.stack((out_ft[..., 1], out_ft[..., 2]), dim=-1))\n        dual_1_ifft = torch.fft.ifft2(out_dual_1, s=(out_dual_1.size(-2), out_dual_1.size(-1)))\n        dual_2_ifft = torch.fft.ifft2(out_dual_2, s=(out_dual_2.size(-2), out_dual_2.size(-1)))\n\n        # Finally, return to the multivector in the spatial domain.\n        output = torch.stack(\n            (\n                dual_1_ifft.real,\n                dual_2_ifft.real,\n                dual_2_ifft.imag,\n                dual_1_ifft.imag,\n            ),\n            dim=-1,\n        )\n\n        return output\n</code></pre>"},{"location":"reference/modules/#cliffordlayers.nn.modules.cliffordfourier.CliffordSpectralConv3d","title":"<code>CliffordSpectralConv3d</code>","text":"<p>             Bases: <code>Module</code></p> <p>3d Clifford Fourier layer. Performs following three steps:     1. Clifford Fourier transform over the multivector of 3d Clifford algebras, based on complex Fourier transforms using pytorch.fft.fftn.     2. Weight multiplication in the Clifford Fourier space using the geometric product.     3. Inverse Clifford Fourier transform, based on inverse complex Fourier transforms using pytorch.fft.ifftn.</p> <p>Parameters:</p> Name Type Description Default <code>g</code> <code>Union[tuple, list, Tensor]</code> <p>Signature of Clifford algebra.</p> required <code>in_channels</code> <code>int</code> <p>Number of input channels.</p> required <code>out_channels</code> <code>int</code> <p>Number of output channels.</p> required <code>modes1</code> <code>int</code> <p>Number of non-zero Fourier modes in the first dimension.</p> required <code>modes2</code> <code>int</code> <p>Number of non-zero Fourier modes in the second dimension.</p> required <code>modes3</code> <code>int</code> <p>Number of non-zero Fourier modes in the second dimension.</p> required <code>multiply</code> <code>bool</code> <p>Multipliation in the Fourier space. If set to False this class only crops high-frequency modes.</p> <code>True</code> Source code in <code>cliffordlayers/nn/modules/cliffordfourier.py</code> <pre><code>class CliffordSpectralConv3d(nn.Module):\n    \"\"\"3d Clifford Fourier layer.\n    Performs following three steps:\n        1. Clifford Fourier transform over the multivector of 3d Clifford algebras, based on complex Fourier transforms using [pytorch.fft.fftn](https://pytorch.org/docs/stable/generated/torch.fft.fftn.html#torch.fft.fftn).\n        2. Weight multiplication in the Clifford Fourier space using the geometric product.\n        3. Inverse Clifford Fourier transform, based on inverse complex Fourier transforms using [pytorch.fft.ifftn](https://pytorch.org/docs/stable/generated/torch.fft.fftn.html#torch.fft.ifftn).\n\n    Args:\n        g ((Union[tuple, list, torch.Tensor]): Signature of Clifford algebra.\n        in_channels (int): Number of input channels.\n        out_channels (int): Number of output channels.\n        modes1 (int): Number of non-zero Fourier modes in the first dimension.\n        modes2 (int): Number of non-zero Fourier modes in the second dimension.\n        modes3 (int): Number of non-zero Fourier modes in the second dimension.\n        multiply (bool): Multipliation in the Fourier space. If set to False this class only crops high-frequency modes.\n\n    \"\"\"\n\n    def __init__(\n        self,\n        g: Union[tuple, list, torch.Tensor],\n        in_channels: int,\n        out_channels: int,\n        modes1: int,\n        modes2: int,\n        modes3: int,\n        multiply: bool = True,\n    ) -&gt; None:\n        super().__init__()\n        sig = CliffordSignature(g)\n        self.g = sig.g\n        self.dim = sig.dim\n        if self.dim != 3:\n            raise ValueError(\"g must be a 3D Clifford algebra\")\n        self.n_blades = sig.n_blades\n\n        self.in_channels = in_channels\n        self.out_channels = out_channels\n        self.modes1 = modes1\n        self.modes2 = modes2\n        self.modes3 = modes3\n        self.multiply = multiply\n\n        # Initialize weight parameters.\n        if self.multiply:\n            scale = 1 / (in_channels * out_channels)\n            self.weights = nn.Parameter(\n                scale\n                * torch.rand(\n                    8,\n                    out_channels,\n                    in_channels,\n                    self.modes1 * 2,\n                    self.modes2 * 2,\n                    self.modes3 * 2,\n                    dtype=torch.float32,\n                )\n            )\n\n    def forward(self, x: torch.Tensor) -&gt; torch.Tensor:\n        # Reshape x such that FFT can be applied to dual pairs.\n        B, _, *D, I = x.shape\n        *_, I = x.shape\n        if not (I == self.n_blades):\n            raise ValueError(f\"Input has {I} blades, but Clifford layer expects {self.n_blades}.\")\n\n        dual_1 = torch.view_as_complex(torch.stack((x[..., 0], x[..., 7]), dim=-1))\n        dual_2 = torch.view_as_complex(torch.stack((x[..., 1], x[..., 6]), dim=-1))\n        dual_3 = torch.view_as_complex(torch.stack((x[..., 2], x[..., 5]), dim=-1))\n        dual_4 = torch.view_as_complex(torch.stack((x[..., 3], x[..., 4]), dim=-1))\n        dual_1_ft = torch.fft.fftn(dual_1, dim=[-3, -2, -1])\n        dual_2_ft = torch.fft.fftn(dual_2, dim=[-3, -2, -1])\n        dual_3_ft = torch.fft.fftn(dual_3, dim=[-3, -2, -1])\n        dual_4_ft = torch.fft.fftn(dual_4, dim=[-3, -2, -1])\n\n        # Add dual pairs again to multivector in the Fourier space.\n        multivector_ft = torch.cat(\n            (\n                dual_1_ft.real,\n                dual_2_ft.real,\n                dual_3_ft.real,\n                dual_4_ft.real,\n                dual_4_ft.imag,\n                dual_3_ft.imag,\n                dual_2_ft.imag,\n                dual_1_ft.imag,\n            ),\n            dim=1,\n        )\n\n        # Reserve Cifford output Fourier modes.\n        out_ft = torch.zeros(\n            B,\n            self.out_channels * self.n_blades,\n            *D,\n            dtype=torch.float,\n            device=multivector_ft.device,\n        )\n\n        # Concatenate positive and negative modes, such that the geometric product can be applied in one go.\n        input_mul = torch.cat(\n            (\n                torch.cat(\n                    (\n                        torch.cat(\n                            (\n                                multivector_ft[:, :, : self.modes1, : self.modes2, : self.modes3],\n                                multivector_ft[:, :, : self.modes1, : self.modes2, -self.modes3 :],\n                            ),\n                            -1,\n                        ),\n                        torch.cat(\n                            (\n                                multivector_ft[:, :, : self.modes1, -self.modes2 :, : self.modes3],\n                                multivector_ft[:, :, : self.modes1, -self.modes2 :, -self.modes3 :],\n                            ),\n                            -1,\n                        ),\n                    ),\n                    -2,\n                ),\n                torch.cat(\n                    (\n                        torch.cat(\n                            (\n                                multivector_ft[:, :, -self.modes1 :, : self.modes2, : self.modes3],\n                                multivector_ft[:, :, -self.modes1 :, : self.modes2, -self.modes3 :],\n                            ),\n                            -1,\n                        ),\n                        torch.cat(\n                            (\n                                multivector_ft[:, :, -self.modes1 :, -self.modes2 :, : self.modes3],\n                                multivector_ft[:, :, -self.modes1 :, -self.modes2 :, -self.modes3 :],\n                            ),\n                            -1,\n                        ),\n                    ),\n                    -2,\n                ),\n            ),\n            -3,\n        )\n\n        # Get Clifford weight tensor and apply the geometric product in the Fourier space.\n        if self.multiply:\n            _, kernel = get_3d_clifford_kernel(self.weights, self.g)\n            output_mul = batchmul3d(input_mul, kernel)\n        else:\n            output_mul = input_mul\n\n        # Fill the output modes, i.e. cut away high-frequency modes.\n        out_ft[:, :, : self.modes1, : self.modes2, : self.modes3] = output_mul[\n            :, :, : self.modes1, : self.modes2, : self.modes3\n        ]\n        out_ft[:, :, : self.modes1, : self.modes2, -self.modes3 :] = output_mul[\n            :, :, : self.modes1, : self.modes2, -self.modes3 :\n        ]\n        out_ft[:, :, : self.modes1, -self.modes2 :, : self.modes3] = output_mul[\n            :, :, : self.modes1, -self.modes2 :, : self.modes3\n        ]\n        out_ft[:, :, : self.modes1, -self.modes2 :, -self.modes3 :] = output_mul[\n            :, :, : self.modes1, -self.modes2 :, -self.modes3 :\n        ]\n        out_ft[:, :, -self.modes1 :, : self.modes2, : self.modes3] = output_mul[\n            :, :, -self.modes1 :, : self.modes2, : self.modes3\n        ]\n        out_ft[:, :, -self.modes1 :, : self.modes2, -self.modes3 :] = output_mul[\n            :, :, : -self.modes1 :, : self.modes2, -self.modes3 :\n        ]\n        out_ft[:, :, -self.modes1 :, -self.modes2 :, : self.modes3] = output_mul[\n            :, :, -self.modes1 :, -self.modes2 :, : self.modes3\n        ]\n        out_ft[:, :, -self.modes1 :, -self.modes2 :, -self.modes3 :] = output_mul[\n            :, :, -self.modes1 :, -self.modes2 :, -self.modes3 :\n        ]\n\n        # Reshape output such that inverse FFTs can be applied to the dual pairs.\n        out_ft = out_ft.reshape(B, I, -1, *out_ft.shape[-3:])\n        B_dim, I_dim, C_dim, *D_dims = range(len(out_ft.shape))\n        out_ft = out_ft.permute(B_dim, C_dim, *D_dims, I_dim)\n\n        out_dual_1 = torch.view_as_complex(torch.stack((out_ft[..., 0], out_ft[..., 7]), dim=-1))\n        out_dual_2 = torch.view_as_complex(torch.stack((out_ft[..., 1], out_ft[..., 6]), dim=-1))\n        out_dual_3 = torch.view_as_complex(torch.stack((out_ft[..., 2], out_ft[..., 5]), dim=-1))\n        out_dual_4 = torch.view_as_complex(torch.stack((out_ft[..., 3], out_ft[..., 4]), dim=-1))\n        dual_1_ifft = torch.fft.ifftn(out_dual_1, s=(out_dual_1.size(-3), out_dual_1.size(-2), out_dual_1.size(-1)))\n        dual_2_ifft = torch.fft.ifftn(out_dual_2, s=(out_dual_2.size(-3), out_dual_2.size(-2), out_dual_2.size(-1)))\n        dual_3_ifft = torch.fft.ifftn(out_dual_3, s=(out_dual_3.size(-3), out_dual_3.size(-2), out_dual_3.size(-1)))\n        dual_4_ifft = torch.fft.ifftn(out_dual_4, s=(out_dual_4.size(-3), out_dual_4.size(-2), out_dual_4.size(-1)))\n\n        # Finally, return to the multivector in the spatial domain.\n        output = torch.stack(\n            (\n                dual_1_ifft.real,\n                dual_2_ifft.real,\n                dual_3_ifft.real,\n                dual_4_ifft.real,\n                dual_4_ifft.imag,\n                dual_3_ifft.imag,\n                dual_2_ifft.imag,\n                dual_1_ifft.imag,\n            ),\n            dim=-1,\n        )\n\n        return output\n</code></pre>"},{"location":"reference/modules/#cliffordlayers.nn.modules.gcan.CliffordG3Conv2d","title":"<code>CliffordG3Conv2d</code>","text":"<p>             Bases: <code>_CliffordG3ConvNd</code></p> <p>2D convolutional layer where the features are vectors in G3.</p> <p>Parameters:</p> Name Type Description Default <code>in_channels</code> <code>int</code> <p>Number of input channels.</p> required <code>out_channels</code> <code>int</code> <p>Number of output channels.</p> required <code>kernel_size</code> <code>int</code> <p>Size of the convolutional kernel. Defaults to 1.</p> <code>1</code> <code>stride</code> <code>int</code> <p>Stride of the convolution operation. Defaults to 1.</p> <code>1</code> <code>padding</code> <code>int or str</code> <p>Padding added to both sides of the input or padding mode. Defaults to 0.</p> <code>0</code> <code>dilation</code> <code>int</code> <p>Dilation rate of the kernel. Defaults to 1.</p> <code>1</code> <code>groups</code> <code>int</code> <p>Number of blocked connections from input channels to output channels. Defaults to 1.</p> <code>1</code> <code>bias</code> <code>bool</code> <p>If True, adds a bias term to the output. Defaults to False.</p> <code>False</code> Source code in <code>cliffordlayers/nn/modules/gcan.py</code> <pre><code>class CliffordG3Conv2d(_CliffordG3ConvNd):\n    \"\"\"\n    2D convolutional layer where the features are vectors in G3.\n\n    Args:\n        in_channels (int): Number of input channels.\n        out_channels (int): Number of output channels.\n        kernel_size (int, optional): Size of the convolutional kernel. Defaults to 1.\n        stride (int, optional): Stride of the convolution operation. Defaults to 1.\n        padding (int or str, optional): Padding added to both sides of the input or padding mode. Defaults to 0.\n        dilation (int, optional): Dilation rate of the kernel. Defaults to 1.\n        groups (int, optional): Number of blocked connections from input channels to output channels. Defaults to 1.\n        bias (bool, optional): If True, adds a bias term to the output. Defaults to False.\n    \"\"\"\n\n    def __init__(\n        self,\n        in_channels: int,\n        out_channels: int,\n        kernel_size: int = 1,\n        stride: int = 1,\n        padding: int = 0,\n        dilation: int = 1,\n        groups: int = 1,\n        bias: bool = False,\n    ):\n        kernel_size_ = _pair(kernel_size)\n        stride_ = _pair(stride)\n        padding_ = padding if isinstance(padding, str) else _pair(padding)\n        dilation_ = _pair(dilation)\n        super().__init__(\n            in_channels=in_channels,\n            out_channels=out_channels,\n            kernel_size=kernel_size_,\n            stride=stride_,\n            padding=padding_,\n            dilation=dilation_,\n            groups=groups,\n            transposed=False,\n            bias=bias,\n        )\n\n    def forward(self, input):\n        x = torch.cat([input[..., 0], input[..., 1], input[..., 2]], dim=1)\n\n        x = clifford_g3convnd(\n            x,\n            self.weights,\n            self.bias,\n            self.stride,\n            self.padding,\n            self.dilation,\n            self.groups,\n        )\n\n        e_0 = x[:, : self.out_channels, :, :]\n        e_1 = x[:, self.out_channels : self.out_channels * 2, :, :]\n        e_2 = x[:, self.out_channels * 2 : self.out_channels * 3, :, :]\n\n        return torch.stack([e_0, e_1, e_2], dim=-1)\n</code></pre>"},{"location":"reference/modules/#cliffordlayers.nn.modules.gcan.CliffordG3ConvTranspose2d","title":"<code>CliffordG3ConvTranspose2d</code>","text":"<p>             Bases: <code>_CliffordG3ConvNd</code></p> <p>2D transposed convolutional layer where the features are vectors in G3.</p> <p>Parameters:</p> Name Type Description Default <code>in_channels</code> <code>int</code> <p>Number of input channels.</p> required <code>out_channels</code> <code>int</code> <p>Number of output channels.</p> required <code>kernel_size</code> <code>int</code> <p>Size of the convolutional kernel. Defaults to 1.</p> <code>1</code> <code>stride</code> <code>int</code> <p>Stride of the convolution operation. Defaults to 1.</p> <code>1</code> <code>padding</code> <code>int or str</code> <p>Padding added to both sides of the input or padding mode. Defaults to 0.</p> <code>0</code> <code>dilation</code> <code>int</code> <p>Dilation rate of the kernel. Defaults to 1.</p> <code>1</code> <code>groups</code> <code>int</code> <p>Number of blocked connections from input channels to output channels. Defaults to 1.</p> <code>1</code> <code>bias</code> <code>bool</code> <p>If True, adds a bias term to the output. Defaults to False.</p> <code>False</code> Source code in <code>cliffordlayers/nn/modules/gcan.py</code> <pre><code>class CliffordG3ConvTranspose2d(_CliffordG3ConvNd):\n    \"\"\"\n    2D transposed convolutional layer where the features are vectors in G3.\n\n    Args:\n        in_channels (int): Number of input channels.\n        out_channels (int): Number of output channels.\n        kernel_size (int, optional): Size of the convolutional kernel. Defaults to 1.\n        stride (int, optional): Stride of the convolution operation. Defaults to 1.\n        padding (int or str, optional): Padding added to both sides of the input or padding mode. Defaults to 0.\n        dilation (int, optional): Dilation rate of the kernel. Defaults to 1.\n        groups (int, optional): Number of blocked connections from input channels to output channels. Defaults to 1.\n        bias (bool, optional): If True, adds a bias term to the output. Defaults to False.\n    \"\"\"\n\n    def __init__(\n        self,\n        in_channels: int,\n        out_channels: int,\n        kernel_size: int = 1,\n        stride: int = 1,\n        padding: int = 0,\n        dilation: int = 1,\n        groups: int = 1,\n        bias: bool = False,\n    ):\n        kernel_size_ = _pair(kernel_size)\n        stride_ = _pair(stride)\n        padding_ = padding if isinstance(padding, str) else _pair(padding)\n        dilation_ = _pair(dilation)\n        super().__init__(\n            in_channels=in_channels,\n            out_channels=out_channels,\n            kernel_size=kernel_size_,\n            stride=stride_,\n            padding=padding_,\n            dilation=dilation_,\n            groups=groups,\n            transposed=True,\n            bias=bias,\n        )\n\n    def forward(self, input):\n        x = torch.cat([input[..., 0], input[..., 1], input[..., 2]], dim=1)\n\n        x = clifford_g3convnd(\n            x,\n            self.weights,\n            self.bias,\n            self.stride,\n            self.padding,\n            self.dilation,\n            self.groups,\n            transposed=True,\n        )\n        e_0 = x[:, : self.out_channels, :, :]\n        e_1 = x[:, self.out_channels : self.out_channels * 2, :, :]\n        e_2 = x[:, self.out_channels * 2 : self.out_channels * 3, :, :]\n\n        return torch.stack([e_0, e_1, e_2], dim=-1)\n</code></pre>"},{"location":"reference/modules/#cliffordlayers.nn.modules.gcan.CliffordG3GroupNorm","title":"<code>CliffordG3GroupNorm</code>","text":"<p>             Bases: <code>Module</code></p> <p>A module that applies group normalization to vectors in G3.</p> <p>Parameters:</p> Name Type Description Default <code>num_groups</code> <code>int</code> <p>Number of groups to normalize over.</p> required <code>num_features</code> <code>int</code> <p>Number of features in the input.</p> required <code>num_blades</code> <code>int</code> <p>Number of blades in the input.</p> required <code>scale_norm</code> <code>bool</code> <p>If True, the output is scaled by the norm of the input. Defaults to False.</p> <code>False</code> Source code in <code>cliffordlayers/nn/modules/gcan.py</code> <pre><code>class CliffordG3GroupNorm(nn.Module):\n    \"\"\"\n    A module that applies group normalization to vectors in G3.\n\n    Args:\n        num_groups (int): Number of groups to normalize over.\n        num_features (int): Number of features in the input.\n        num_blades (int): Number of blades in the input.\n        scale_norm (bool, optional): If True, the output is scaled by the norm of the input. Defaults to False.\n    \"\"\"\n\n    def __init__(self, num_groups, num_features, num_blades, scale_norm=False):\n        super().__init__()\n        self.weight = nn.Parameter(torch.ones(num_features))\n        self.bias = nn.Parameter(torch.zeros(num_features, num_blades))\n        self.num_groups = num_groups\n        self.scale_norm = scale_norm\n        self.num_blades = num_blades\n        self.num_features = num_features\n\n    def forward(self, x):\n        N, C, *D, I = x.size()\n        G = self.num_groups\n        assert C % G == 0\n\n        x = x.view(N, G, -1, I)\n        mean = x.mean(-2, keepdim=True)\n        x = x - mean\n        if self.scale_norm:\n            norm = x.norm(dim=-1, keepdim=True).mean(dim=-2, keepdims=True)\n            x = x / norm\n\n        x = x.view(len(x), self.num_features, -1, self.num_blades)\n\n        return (x * self.weight[None, :, None, None] + self.bias[None, :, None]).view(N, C, *D, I)\n</code></pre>"},{"location":"reference/modules/#cliffordlayers.nn.modules.gcan.CliffordG3LinearVSiLU","title":"<code>CliffordG3LinearVSiLU</code>","text":"<p>             Bases: <code>Module</code></p> <p>A module that applies the vector SiLU using a linear combination to vectors in G3.</p> <p>Parameters:</p> Name Type Description Default <code>channels</code> <code>int</code> <p>Number of channels in the input.</p> required Source code in <code>cliffordlayers/nn/modules/gcan.py</code> <pre><code>class CliffordG3LinearVSiLU(nn.Module):\n    \"\"\"\n    A module that applies the vector SiLU using a linear combination to vectors in G3.\n\n    Args:\n        channels (int): Number of channels in the input.\n    \"\"\"\n\n    def __init__(self, channels):\n        super().__init__()\n        self.conv = nn.Conv3d(channels, channels, (1, 1, 3), groups=channels)\n\n    def forward(self, input):\n        return input * torch.sigmoid(self.conv(input))\n</code></pre>"},{"location":"reference/modules/#cliffordlayers.nn.modules.gcan.CliffordG3MeanVSiLU","title":"<code>CliffordG3MeanVSiLU</code>","text":"<p>             Bases: <code>Module</code></p> <p>A module that applies the vector SiLU using vector mean to vectors in G3.</p> Source code in <code>cliffordlayers/nn/modules/gcan.py</code> <pre><code>class CliffordG3MeanVSiLU(nn.Module):\n    \"\"\"\n    A module that applies the vector SiLU using vector mean to vectors in G3.\n    \"\"\"\n\n    def __init__(self):\n        super().__init__()\n\n    def forward(self, input):\n        return torch.sigmoid(input.mean(-1, keepdim=True)) * input\n</code></pre>"},{"location":"reference/modules/#cliffordlayers.nn.modules.gcan.CliffordG3SumVSiLU","title":"<code>CliffordG3SumVSiLU</code>","text":"<p>             Bases: <code>Module</code></p> <p>A module that applies the vector SiLU using vector sum to vectors in G3.</p> Source code in <code>cliffordlayers/nn/modules/gcan.py</code> <pre><code>class CliffordG3SumVSiLU(nn.Module):\n    \"\"\"\n    A module that applies the vector SiLU using vector sum to vectors in G3.\n    \"\"\"\n\n    def __init__(self):\n        super().__init__()\n\n    def forward(self, input):\n        return torch.sigmoid(input.sum(-1, keepdim=True)) * input\n</code></pre>"},{"location":"reference/modules/#cliffordlayers.nn.modules.gcan.MultiVectorAct","title":"<code>MultiVectorAct</code>","text":"<p>             Bases: <code>Module</code></p> <p>A module to apply multivector activations to the input.</p> <p>Parameters:</p> Name Type Description Default <code>channels</code> <code>int</code> <p>Number of channels in the input.</p> required <code>algebra</code> <p>The algebra object that defines the geometric product.</p> required <code>input_blades</code> <code>(list, tuple)</code> <p>The nonnegative input blades.</p> required <code>kernel_blades</code> <code>(list, tuple)</code> <p>The blades that will be used to compute the activation. Defaults to all input blades.</p> <code>None</code> <code>agg</code> <code>str</code> <p>The aggregation method to be used. Options include \"linear\", \"sum\", and \"mean\". Defaults to \"linear\".</p> <code>'linear'</code> Source code in <code>cliffordlayers/nn/modules/gcan.py</code> <pre><code>class MultiVectorAct(nn.Module):\n    \"\"\"\n    A module to apply multivector activations to the input.\n\n    Args:\n        channels (int): Number of channels in the input.\n        algebra: The algebra object that defines the geometric product.\n        input_blades (list, tuple): The nonnegative input blades.\n        kernel_blades (list, tuple, optional): The blades that will be used to compute the activation. Defaults to all input blades.\n        agg (str, optional): The aggregation method to be used. Options include \"linear\", \"sum\", and \"mean\". Defaults to \"linear\".\n    \"\"\"\n\n    def __init__(self, channels, algebra, input_blades, kernel_blades=None, agg=\"linear\"):\n        super().__init__()\n        self.algebra = algebra\n        self.input_blades = tuple(input_blades)\n        if kernel_blades is not None:\n            self.kernel_blades = tuple(kernel_blades)\n        else:\n            self.kernel_blades = self.input_blades\n\n        if agg == \"linear\":\n            self.conv = nn.Conv1d(channels, channels, kernel_size=len(self.kernel_blades), groups=channels)\n        self.agg = agg\n\n    def forward(self, input):\n        v = self.algebra.embed(input, self.input_blades)\n        if self.agg == \"linear\":\n            v = v * torch.sigmoid(self.conv(v[..., self.kernel_blades]))\n        elif self.agg == \"sum\":\n            v = v * torch.sigmoid(v[..., self.kernel_blades].sum(dim=-1, keepdim=True))\n        elif self.agg == \"mean\":\n            v = v * torch.sigmoid(v[..., self.kernel_blades].mean(dim=-1, keepdim=True))\n        else:\n            raise ValueError(f\"Aggregation {self.agg} not implemented.\")\n        v = self.algebra.get(v, self.input_blades)\n        return v\n</code></pre>"},{"location":"reference/modules/#cliffordlayers.nn.modules.gcan.PGAConjugateLinear","title":"<code>PGAConjugateLinear</code>","text":"<p>             Bases: <code>Module</code></p> <p>Linear layer that applies the PGA conjugation to the input.</p> <p>Parameters:</p> Name Type Description Default <code>in_features</code> <code>int</code> <p>Number of input features.</p> required <code>out_features</code> <code>int</code> <p>Number of output features.</p> required <code>algebra</code> <code>Algebra</code> <p>Algebra object that defines the geometric product.</p> required <code>input_blades</code> <code>tuple</code> <p>Nonnegative blades of the input multivectors.</p> required <code>action_blades</code> <code>tuple</code> <p>Blades of the action. Defaults to (0, 5, 6, 7, 8, 9, 10, 15),                              which encodes rotation and translation.</p> <code>(0, 5, 6, 7, 8, 9, 10, 15)</code> Source code in <code>cliffordlayers/nn/modules/gcan.py</code> <pre><code>class PGAConjugateLinear(nn.Module):\n    \"\"\"\n    Linear layer that applies the PGA conjugation to the input.\n\n    Args:\n        in_features (int): Number of input features.\n        out_features (int): Number of output features.\n        algebra (Algebra): Algebra object that defines the geometric product.\n        input_blades (tuple): Nonnegative blades of the input multivectors.\n        action_blades (tuple, optional): Blades of the action. Defaults to (0, 5, 6, 7, 8, 9, 10, 15),\n                                         which encodes rotation and translation.\n    \"\"\"\n\n    def __init__(\n        self,\n        in_features,\n        out_features,\n        algebra,\n        input_blades,\n        action_blades=(0, 5, 6, 7, 8, 9, 10, 15),\n    ):\n        super().__init__()\n        assert torch.all(algebra.metric == torch.tensor([0, 1, 1, 1]))\n        self.input_blades = input_blades\n        self.in_features = in_features\n        self.out_features = out_features\n        self.algebra = algebra\n        self.action_blades = action_blades\n        self.n_action_blades = len(action_blades)\n        self._action = nn.Parameter(torch.empty(out_features, in_features, self.n_action_blades))\n        self.weight = nn.Parameter(torch.empty(out_features, in_features))\n        self.embed_e0 = nn.Parameter(torch.zeros(in_features, 1))\n\n        self.inverse = algebra.reverse\n\n        self.reset_parameters()\n\n    def reset_parameters(self):\n        # Init the rotation parts uniformly.\n        torch.nn.init.uniform_(self._action[..., 0], -1, 1)\n        torch.nn.init.uniform_(self._action[..., 4:7], -1, 1)\n\n        # Init the translation parts with zeros.\n        torch.nn.init.zeros_(self._action[..., 1:4])\n        torch.nn.init.zeros_(self._action[..., 7])\n\n        norm = self.algebra.norm(self.algebra.embed(self._action.data, self.action_blades))\n        assert torch.allclose(norm[..., 1:], torch.tensor(0.0), atol=1e-3)\n        norm = norm[..., :1]\n        self._action.data = self._action.data / norm\n\n        torch.nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n\n    @property\n    def action(self):\n        return self.algebra.embed(self._action, self.action_blades)\n\n    def forward(self, input):\n        M = self.algebra.cayley\n        k = self.action\n        k_ = self.inverse(k)\n        x = self.algebra.embed(input, self.input_blades)\n        x[..., 14:15] = self.embed_e0\n        # x[..., 14:15] = 1\n\n        k_l = get_clifford_left_kernel(M, k, flatten=False)\n        k_r = get_clifford_right_kernel(M, k_, flatten=False)\n\n        x = torch.einsum(\"oi,poqi,qori,bir-&gt;bop\", self.weight, k_r, k_l, x)\n\n        x = self.algebra.get(x, self.input_blades)\n\n        return x\n</code></pre>"},{"location":"reference/modules/#cliffordlayers.nn.modules.gcan.get_clifford_left_kernel","title":"<code>get_clifford_left_kernel(M, w, flatten=True)</code>","text":"<p>Obtains the matrix that computes the geometric product from the left. When the output is flattened, it can be used to apply a fully connected layer on the multivectors.</p> <p>Parameters:</p> Name Type Description Default <code>M</code> <code>Tensor</code> <p>Cayley table that defines the geometric relation.</p> required <code>w</code> <code>Tensor</code> <p>Input tensor with shape (o, i, c) where o is the number of output channels,         i is the number of input channels, and c is the number of blades.</p> required <code>flatten</code> <code>bool</code> <p>If True, the resulting matrix will be reshaped for subsequent                       fully connected operations. Defaults to True.</p> <code>True</code> Source code in <code>cliffordlayers/nn/modules/gcan.py</code> <pre><code>def get_clifford_left_kernel(M, w, flatten=True):\n    \"\"\"\n    Obtains the matrix that computes the geometric product from the left.\n    When the output is flattened, it can be used to apply a fully connected\n    layer on the multivectors.\n\n    Args:\n        M (Tensor): Cayley table that defines the geometric relation.\n        w (Tensor): Input tensor with shape (o, i, c) where o is the number of output channels,\n                    i is the number of input channels, and c is the number of blades.\n        flatten (bool, optional): If True, the resulting matrix will be reshaped for subsequent\n                                  fully connected operations. Defaults to True.\n\n    \"\"\"\n    o, i, c = w.size()\n    k = torch.einsum(\"ijk, pqi-&gt;jpkq\", M, w)\n    if flatten:\n        k = k.reshape(o * c, i * c)\n    return k\n</code></pre>"},{"location":"reference/modules/#cliffordlayers.nn.modules.gcan.get_clifford_right_kernel","title":"<code>get_clifford_right_kernel(M, w, flatten=True)</code>","text":"<p>Obtains the matrix that computes the geometric product from the right. When the output is flattened, it can be used to apply a fully connected layer on the multivectors.</p> <p>Parameters:</p> Name Type Description Default <code>M</code> <code>Tensor</code> <p>Cayley table that defines the geometric relation.</p> required <code>w</code> <code>Tensor</code> <p>Input tensor with shape (o, i, c) where o is the number of output channels,         i is the number of input channels, and c is the number of blades.</p> required <code>flatten</code> <code>bool</code> <p>If True, the resulting matrix will be reshaped for subsequent                         fully connected operations. Defaults to True.</p> <code>True</code> Source code in <code>cliffordlayers/nn/modules/gcan.py</code> <pre><code>def get_clifford_right_kernel(M, w, flatten=True):\n    \"\"\"\n    Obtains the matrix that computes the geometric product from the right.\n    When the output is flattened, it can be used to apply a fully connected\n    layer on the multivectors.\n\n    Args:\n        M (Tensor): Cayley table that defines the geometric relation.\n        w (Tensor): Input tensor with shape (o, i, c) where o is the number of output channels,\n                    i is the number of input channels, and c is the number of blades.\n        flatten (bool, optional): If True, the resulting matrix will be reshaped for subsequent\n                                    fully connected operations. Defaults to True.\n    \"\"\"\n    o, i, c = w.size()\n    k = torch.einsum(\"ijk, pqk-&gt;jpiq\", M, w)\n    if flatten:\n        k = k.reshape(o * c, i * c)\n    return k\n</code></pre>"},{"location":"reference/modules/#cliffordlayers.nn.modules.batchnorm.CliffordBatchNorm1d","title":"<code>CliffordBatchNorm1d</code>","text":"<p>             Bases: <code>_CliffordBatchNorm</code></p> <p>Clifford batch normalization for 2D or 3D data.</p> <p>The input data is expected to be at least 3d, with shape <code>(B, C, D, I)</code>, where <code>B</code> is the batch dimension, <code>C</code> the channels/features, and D the remaining dimension (if present). See [torch.nn.BatchNorm1d] for details.</p> Source code in <code>cliffordlayers/nn/modules/batchnorm.py</code> <pre><code>class CliffordBatchNorm1d(_CliffordBatchNorm):\n    \"\"\"Clifford batch normalization for 2D or 3D data.\n\n    The input data is expected to be at least 3d, with shape `(B, C, D, I)`,\n    where `B` is the batch dimension, `C` the channels/features, and D the remaining dimension (if present).\n    See [torch.nn.BatchNorm1d] for details.\n    \"\"\"\n\n    def _check_input_dim(self, x):\n        *_, I = x.shape\n        if not I == self.n_blades:\n            raise ValueError(f\"Wrong number of Clifford blades. Expected {self.n_blades} blades, but {I} were given.\")\n        if x.dim() != 3 and x.dim() != 4:\n            raise ValueError(f\"Expected 3D or 4D input (got {x.dim()}D input).\")\n</code></pre>"},{"location":"reference/modules/#cliffordlayers.nn.modules.batchnorm.CliffordBatchNorm2d","title":"<code>CliffordBatchNorm2d</code>","text":"<p>             Bases: <code>_CliffordBatchNorm</code></p> <p>Clifford batch normalization for 4D data.</p> <p>The input data is expected to be 4d, with shape <code>(B, C, *D, I)</code>, where <code>B</code> is the batch dimension, <code>C</code> the channels/features, and D the remaining dimension 2 dimensions. See torch.nn.BatchNorm2d for details.</p> Source code in <code>cliffordlayers/nn/modules/batchnorm.py</code> <pre><code>class CliffordBatchNorm2d(_CliffordBatchNorm):\n    \"\"\"Clifford batch normalization for 4D data.\n\n    The input data is expected to be 4d, with shape `(B, C, *D, I)`,\n    where `B` is the batch dimension, `C` the channels/features, and D the remaining dimension 2 dimensions.\n    See [torch.nn.BatchNorm2d][] for details.\n    \"\"\"\n\n    def _check_input_dim(self, x):\n        *_, I = x.shape\n        if not I == self.n_blades:\n            raise ValueError(f\"Wrong number of Clifford blades. Expected {self.n_blades} blades, but {I} were given.\")\n        if x.dim() != 5:\n            raise ValueError(f\"Expected 3D or 4D input (got {x.dim()}D input).\")\n</code></pre>"},{"location":"reference/modules/#cliffordlayers.nn.modules.batchnorm.CliffordBatchNorm3d","title":"<code>CliffordBatchNorm3d</code>","text":"<p>             Bases: <code>_CliffordBatchNorm</code></p> <p>Clifford batch normalization for 5D data. The input data is expected to be 5d, with shape <code>(B, C, *D, I)</code>, where <code>B</code> is the batch dimension, <code>C</code> the channels/features, and D the remaining dimension 3 dimensions. See torch.nn.BatchNorm2d for details.</p> Source code in <code>cliffordlayers/nn/modules/batchnorm.py</code> <pre><code>class CliffordBatchNorm3d(_CliffordBatchNorm):\n    \"\"\"Clifford batch normalization for 5D data.\n    The input data is expected to be 5d, with shape `(B, C, *D, I)`,\n    where `B` is the batch dimension, `C` the channels/features, and D the remaining dimension 3 dimensions.\n    See [torch.nn.BatchNorm2d][] for details.\n    \"\"\"\n\n    def _check_input_dim(self, x):\n        *_, I = x.shape\n        if not I == self.n_blades:\n            raise ValueError(f\"Wrong number of Clifford blades. Expected {self.n_blades} blades, but {I} were given.\")\n        if x.dim() != 6:\n            raise ValueError(f\"Expected 3D or 4D input (got {x.dim()}D input).\")\n</code></pre>"},{"location":"reference/modules/#cliffordlayers.nn.modules.batchnorm.ComplexBatchNorm1d","title":"<code>ComplexBatchNorm1d</code>","text":"<p>             Bases: <code>_ComplexBatchNorm</code></p> <p>Complex-valued batch normalization for 2D or 3D data.</p> <p>The input complex-valued data is expected to be at least 2d, with shape <code>(B, C, D)</code>, where <code>B</code> is the batch dimension, <code>C</code> the channels/features, and D the remaining dimension (if present). See torch.nn.BatchNorm1d for details.</p> Source code in <code>cliffordlayers/nn/modules/batchnorm.py</code> <pre><code>class ComplexBatchNorm1d(_ComplexBatchNorm):\n    \"\"\"Complex-valued batch normalization for 2D or 3D data.\n\n    The input complex-valued data is expected to be at least 2d, with shape `(B, C, D)`,\n    where `B` is the batch dimension, `C` the channels/features, and D the remaining dimension (if present).\n    See [torch.nn.BatchNorm1d][] for details.\n    \"\"\"\n\n    def _check_input_dim(self, x):\n        if x.dim() != 2 and x.dim() != 3:\n            raise ValueError(f\"Expected 2D or 3D input (got {x.dim()}D input).\")\n</code></pre>"},{"location":"reference/modules/#cliffordlayers.nn.modules.batchnorm.ComplexBatchNorm2d","title":"<code>ComplexBatchNorm2d</code>","text":"<p>             Bases: <code>_ComplexBatchNorm</code></p> <p>Complex-valued batch normalization for 4D data.</p> <p>The input complex-valued data is expected to be 4d, with shape <code>(B, C, *D)</code>, where <code>B</code> is the batch dimension, <code>C</code> the channels/features, and D the remaining 2 dimensions. See torch.nn.BatchNorm2d for details.</p> Source code in <code>cliffordlayers/nn/modules/batchnorm.py</code> <pre><code>class ComplexBatchNorm2d(_ComplexBatchNorm):\n    \"\"\"Complex-valued batch normalization for 4D data.\n\n    The input complex-valued data is expected to be 4d, with shape `(B, C, *D)`,\n    where `B` is the batch dimension, `C` the channels/features, and D the remaining 2 dimensions.\n    See [torch.nn.BatchNorm2d][] for details.\n    \"\"\"\n\n    def _check_input_dim(self, x):\n        if x.dim() != 4:\n            raise ValueError(f\"Expected 4D input (got {x.dim()}D input).\")\n</code></pre>"},{"location":"reference/modules/#cliffordlayers.nn.modules.batchnorm.ComplexBatchNorm3d","title":"<code>ComplexBatchNorm3d</code>","text":"<p>             Bases: <code>_ComplexBatchNorm</code></p> <p>Complex-valued batch normalization for 5D data.</p> <p>The input complex-valued data is expected to be 5d, with shape <code>(B, C, *D)</code>, where <code>B</code> is the batch dimension, <code>C</code> the channels/features, and D the remaining 3 dimensions. See torch.nn.BatchNorm3d for details.</p> Source code in <code>cliffordlayers/nn/modules/batchnorm.py</code> <pre><code>class ComplexBatchNorm3d(_ComplexBatchNorm):\n    \"\"\"Complex-valued batch normalization for 5D data.\n\n    The input complex-valued data is expected to be 5d, with shape `(B, C, *D)`,\n    where `B` is the batch dimension, `C` the channels/features, and D the remaining 3 dimensions.\n    See [torch.nn.BatchNorm3d][] for details.\n    \"\"\"\n\n    def _check_input_dim(self, x):\n        if x.dim() != 5:\n            raise ValueError(f\"Expected 5D input (got {x.dim()}D input).\")\n</code></pre>"},{"location":"reference/modules/#cliffordlayers.nn.modules.groupnorm.CliffordGroupNorm1d","title":"<code>CliffordGroupNorm1d</code>","text":"<p>             Bases: <code>_CliffordGroupNorm</code></p> <p>Clifford group normalization for 2D or 3D data.</p> <p>The input data is expected to be at least 3d, with shape <code>(B, C, D, I)</code>, where <code>B</code> is the batch dimension, <code>C</code> the channels/features, and D the remaining dimension (if present).</p> Source code in <code>cliffordlayers/nn/modules/groupnorm.py</code> <pre><code>class CliffordGroupNorm1d(_CliffordGroupNorm):\n    \"\"\"Clifford group normalization for 2D or 3D data.\n\n    The input data is expected to be at least 3d, with shape `(B, C, D, I)`,\n    where `B` is the batch dimension, `C` the channels/features, and D the remaining dimension (if present).\n    \"\"\"\n\n    def _check_input_dim(self, x):\n        *_, I = x.shape\n        if not I == self.n_blades:\n            raise ValueError(f\"Wrong number of Clifford blades. Expected {self.n_blades} blades, but {I} were given.\")\n        if x.dim() != 3 and x.dim() != 4:\n            raise ValueError(f\"Expected 3D or 4D input (got {x.dim()}D input).\")\n</code></pre>"},{"location":"reference/modules/#cliffordlayers.nn.modules.groupnorm.CliffordGroupNorm2d","title":"<code>CliffordGroupNorm2d</code>","text":"<p>             Bases: <code>_CliffordGroupNorm</code></p> <p>Clifford group normalization for 4D data.</p> <p>The input data is expected to be 4D, with shape <code>(B, C, *D, I)</code>, where <code>B</code> is the batch dimension, <code>C</code> the channels/features, and D the remaining 2 dimensions.</p> Source code in <code>cliffordlayers/nn/modules/groupnorm.py</code> <pre><code>class CliffordGroupNorm2d(_CliffordGroupNorm):\n    \"\"\"Clifford group normalization for 4D data.\n\n    The input data is expected to be 4D, with shape `(B, C, *D, I)`,\n    where `B` is the batch dimension, `C` the channels/features, and D the remaining 2 dimensions.\n    \"\"\"\n\n    def _check_input_dim(self, x):\n        *_, I = x.shape\n        if not I == self.n_blades:\n            raise ValueError(f\"Wrong number of Clifford blades. Expected {self.n_blades} blades, but {I} were given.\")\n        if x.dim() != 5:\n            raise ValueError(f\"Expected 3D or 4D input (got {x.dim()}D input).\")\n</code></pre>"},{"location":"reference/modules/#cliffordlayers.nn.modules.groupnorm.CliffordGroupNorm3d","title":"<code>CliffordGroupNorm3d</code>","text":"<p>             Bases: <code>_CliffordGroupNorm</code></p> <p>Clifford group normalization for 4D data.</p> <p>The input data is expected to be 5D, with shape <code>(B, C, *D, I)</code>, where <code>B</code> is the batch dimension, <code>C</code> the channels/features, and D the remaining 3 dimensions.</p> Source code in <code>cliffordlayers/nn/modules/groupnorm.py</code> <pre><code>class CliffordGroupNorm3d(_CliffordGroupNorm):\n    \"\"\"Clifford group normalization for 4D data.\n\n    The input data is expected to be 5D, with shape `(B, C, *D, I)`,\n    where `B` is the batch dimension, `C` the channels/features, and D the remaining 3 dimensions.\n    \"\"\"\n\n    def _check_input_dim(self, x):\n        *_, I = x.shape\n        if not I == self.n_blades:\n            raise ValueError(f\"Wrong number of Clifford blades. Expected {self.n_blades} blades, but {I} were given.\")\n        if x.dim() != 6:\n            raise ValueError(f\"Expected 3D or 4D input (got {x.dim()}D input).\")\n</code></pre>"},{"location":"reference/modules/#cliffordlayers.nn.modules.groupnorm.ComplexGroupNorm1d","title":"<code>ComplexGroupNorm1d</code>","text":"<p>             Bases: <code>_ComplexGroupNorm</code></p> <p>Complex-valued group normalization for 2D or 3D data.</p> <p>The input complex-valued data is expected to be at least 2d, with shape <code>(B, C, D)</code>, where <code>B</code> is the batch dimension, <code>C</code> the channels/features, and D the remaining dimension (if present).</p> Source code in <code>cliffordlayers/nn/modules/groupnorm.py</code> <pre><code>class ComplexGroupNorm1d(_ComplexGroupNorm):\n    \"\"\"Complex-valued group normalization for 2D or 3D data.\n\n    The input complex-valued data is expected to be at least 2d, with shape `(B, C, D)`,\n    where `B` is the batch dimension, `C` the channels/features, and D the remaining dimension (if present).\n    \"\"\"\n\n    def _check_input_dim(self, x):\n        if x.dim() != 2 and x.dim() != 3:\n            raise ValueError(f\"Expected 2D or 3D input (got {x.dim()}D input).\")\n</code></pre>"},{"location":"reference/modules/#cliffordlayers.nn.modules.groupnorm.ComplexGroupNorm2d","title":"<code>ComplexGroupNorm2d</code>","text":"<p>             Bases: <code>_ComplexGroupNorm</code></p> <p>Complex-valued group normalization for 4 data.</p> <p>The input complex-valued data is expected to be 4d, with shape <code>(B, C, *D)</code>, where <code>B</code> is the batch dimension, <code>C</code> the channels/features, and D the remaining 2 dimensions.</p> Source code in <code>cliffordlayers/nn/modules/groupnorm.py</code> <pre><code>class ComplexGroupNorm2d(_ComplexGroupNorm):\n    \"\"\"Complex-valued group normalization for 4 data.\n\n    The input complex-valued data is expected to be 4d, with shape `(B, C, *D)`,\n    where `B` is the batch dimension, `C` the channels/features, and D the remaining 2 dimensions.\n    \"\"\"\n\n    def _check_input_dim(self, x):\n        if x.dim() != 4:\n            raise ValueError(f\"Expected 4D input (got {x.dim()}D input).\")\n</code></pre>"},{"location":"reference/modules/#cliffordlayers.nn.modules.groupnorm.ComplexGroupNorm3d","title":"<code>ComplexGroupNorm3d</code>","text":"<p>             Bases: <code>_ComplexGroupNorm</code></p> <p>Complex-valued group normalization for 5 data.</p> <p>The input complex-valued data is expected to be 5d, with shape <code>(B, C, *D)</code>, where <code>B</code> is the batch dimension, <code>C</code> the channels/features, and D the remaining 3 dimensions.</p> Source code in <code>cliffordlayers/nn/modules/groupnorm.py</code> <pre><code>class ComplexGroupNorm3d(_ComplexGroupNorm):\n    \"\"\"Complex-valued group normalization for 5 data.\n\n    The input complex-valued data is expected to be 5d, with shape `(B, C, *D)`,\n    where `B` is the batch dimension, `C` the channels/features, and D the remaining 3 dimensions.\n    \"\"\"\n\n    def _check_input_dim(self, x):\n        if x.dim() != 5:\n            raise ValueError(f\"Expected 4D input (got {x.dim()}D input).\")\n</code></pre>"}]}